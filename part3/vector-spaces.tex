\chapter{Vector Spaces}
Abstract algebra has three core structures -- groups, rings, and fields. So far, we have looked at groups and rings in detail, and touched on some basic properties of fields. However, to properly explore the structure of fields, we need to cover the basics of vector spaces, which are typically covered in a linear algebra course. We provide a concise overview of vectors and vector spaces here.

\section{What is a Vector Space?}
We first look at what a vector space is.
\begin{definition}
    A \textbf{vector space}\index{vector space} over a field $F$ is a non-empty set $V$ together with two operations,
    \begin{itemize}
        \item \textbf{(vector) addition}\index{vector space!vector addition}, denoted by $+$, where for $\textbf{u}, \textbf{v} \in V$ it produces a new element $\textbf{u} + \textbf{v} \in V$; and
        \item \textbf{scalar multiplication}\index{vector space!scalar multiplication}, which assigns an $a \in F$ and a $\textbf{u} \in V$ to another element in $V$, denoted by $a\textbf{u} \in V$,
    \end{itemize}
    such that it satisfies the \textbf{vector space axioms}\index{axiom!vector space} listed below.
    \begin{itemize}
        \item \textbf{Addition-Abelian}\index{axiom!vector space!addition-abelian}: $(V, +)$ forms an abelian group.
        \item \textbf{Multiplication-Identity}\index{axiom!vector space!multiplication-identity}: For all $\textbf{u} \in V$ we have $1\textbf{u} = \textbf{u}$, where $1 \in F$ denotes the multiplicative identity of $F$.
        \item \textbf{Multiplication-Compatibility}\index{axiom!vector space!multiplication-compatibility}: For all $a,b  \in F$ and $\textbf{u} \in V$ we have $a(b\textbf{u}) = (ab)\textbf{u}$.
        \item \textbf{Distributivity-Addition}\index{axiom!vector space!distributivity-addition}: For all $a \in F$ and $\textbf{u}, \textbf{v} \in V$ we have $a(\textbf{u} + \textbf{v}) = a\textbf{u} + a\textbf{v}$.
        \item \textbf{Distributivity-Scalar}\index{axiom!vector space!distributivity-scalar}: For all $a, b \in F$ and $\textbf{u} \in V$ we have $(a+b)\textbf{u} = a\textbf{u} + b\textbf{u}$.
    \end{itemize}
\end{definition}

To avoid confusion with denoting elements from these two sets, we adopt the following conventions regarding notation.
\begin{itemize}
    \item Elements in $F$ will generally be denoted by letters from the beginning of the alphabet. For example, $a, b, c, d \in F$.
    \item Elements in $V$ will be indicated with boldface and are generally denoted by letters near the end of the alphabet. For example, $\textbf{u}, \textbf{v}, \textbf{w} \in V$.
    \item The additive identity of the group $(V, +)$ will be denoted $\textbf{0}$, a boldface zero.
    \item Define $\textbf{u} - \textbf{v}$ as $\textbf{u} + (-\textbf{v})$, where $-\textbf{v}$ denotes the inverse of $\textbf{v}$ in the group $(V, +)$.
\end{itemize}

\begin{definition}
    Let $V$ be a vector space over a field $F$.
    \begin{itemize}
        \item Elements of $V$ are called \textbf{vectors}\index{vector}.
        \item Elements of $F$ are called \textbf{scalars}\index{scalar}.
    \end{itemize}
\end{definition}

We look at some elementary examples of vector spaces.

\begin{example}\label{example-R^n-is-vector-space}
    The set $\R^n = \{(a_1, a_2, \dots, a_n) \vert a_i \in \R\}$ is a vector space over the field $\R$ with the `natural' choices of addition
    \[
        (a_1, a_2, \dots, a_n) + (b_1, b_2, \dots, b_n) = (a_1 + b_1, a_2 + b_2, \dots, a_n + b_n)
    \]
    and scalar multiplication
    \[
        k(a_1, a_2, \dots, a_n) = (ka_1, ka_2, \dots, ka_n).
    \]

    Let's explicitly prove that $\R^n$ is indeed a vector space over $\R$ using these operations. We need to prove the five vector space axioms.
    \begin{itemize}
        \item \textbf{Addition-Abelian}: \myref{exercise-R^n-is-abelian-group} (later) shows that $(\R^n, +)$ is an abelian group.
        
        \item \textbf{Multiplication-Identity}: Let $(a_1, a_2, \dots, a_n) \in \R^n$. We see
        \begin{align*}
            1(a_1, a_2, \dots, a_n) &= (1a_1, 1a_2, \dots, 1a_n)\\
            &= (a_1, a_2, \dots, a_n)
        \end{align*}
        so this axiom is satisfied.

        \item \textbf{Multiplication-Compatibility}: Let $p, q \in \R$ and $(a_1, a_2, \dots, a_n) \in \R^n$. Note
        \begin{align*}
            p\left(q(a_1, a_2, \dots, a_n)\right) &= p(qa_1, qa_2, \dots, qa_n)\\
            &= (pqa_1, pqa_2, \dots, pqa_n)\\
            &= (pq)(a_1, a_2, \dots, a_n)
        \end{align*}
        so this axiom is satisfied.
        
        \item \textbf{Distributivity-Addition}: Let $k \in \R$ and $(a_1, a_2, \dots, a_n), (b_1, b_2, \dots, b_n) \in \R^n$. We see
        \begin{align*}
            k\left((a_1, a_2, \dots, a_n) + (b_1, b_2, \dots, b_n)\right) &= k(a_1 + b_1, a_2 + b_2, \dots, a_n + b_n)\\
            &= (k(a_1 + b_1), k(a_2 + b_2), \dots, k(a_n + b_n))\\
            &= (ka_1 + kb_1, ka_2 + kb_2, \dots, ka_n + kb_n)\\
            &= (ka_1, ka_2, \dots, ka_n) + (kb_1, kb_2, \dots, kb_n)\\
            &= k(a_1, a_2, \dots, a_n) + k(b_1, b_2, \dots, b_n)
        \end{align*}
        which shows that the axiom is satisfied.
        
        \item \textbf{Distributivity-Scalar}: Let $p, q \in \R$ and $(a_1, a_2, \dots, a_n) \in \R^n$. Then
        \begin{align*}
            (p+q)(a_1, a_2, \dots, a_n) &= ((p+q)a_1, (p+q)a_2, \dots, (p+q)a_n)\\
            &= (pa_1 + qa_1, pa_2 + qa_2, \dots, pa_n + qa_n)\\
            &= (pa_1, pa_2, \dots, pa_n) + (qa_1, qa_2, \dots, qa_n)\\
            &= p(a_1, a_2, \dots, a_n) + q(a_1, a_2, \dots, a_n).
        \end{align*}
        Therefore this axiom is satisfied.
    \end{itemize}
    
    Since all the vector space axioms are satisfied, we proved that $\R^n$ is a vector space over the field $\R$.
\end{example}

\begin{example}\label{example-polynomial-ring-over-field-is-vector-space}
    Let $F$ be a field. We show that the polynomial ring $F[x]$ is a vector space over $F$, where vector addition is simply polynomial addition and scalar multiplication by $r \in F$ is polynomial multiplication by the constant polynomial $r$.
    \begin{itemize}
        \item \textbf{Addition-Abelian}: We have repeatedly shown that $(R[x], +)$ is a commutative ring for any ring $R$, so it also applies to the field $F$.
        
        \item \textbf{Multiplication-Identity}: Let $f(x) \in F[x]$. Note $1f(x) = f(x)$ since 1 is the multiplicative identity of $F$.

        \item \textbf{Multiplication-Compatibility}: Let $a, b \in F$ and $f(x) \in F$. Then clearly $a(bf(x)) = (ab)f(x)$ by polynomial multiplication rules.
        
        \item \textbf{Distributivity-Addition}: Let $a \in F$ and $f(x), g(x) \in F[x]$. Then we know from polynomial multiplication that $a(f(x) + g(x)) = af(x) + ag(x)$.
        
        \item \textbf{Distributivity-Scalar}: Let $a, b \in F$ and $f(x) \in F[x]$. Then we also know from polynomial multiplication that $(a+b)f(x) = af(x) + bf(x)$.
    \end{itemize}
    Therefore $F[x]$ is a vector space over $F$.
\end{example}

\begin{example}
    $\C$ is a vector space over $\R$ under the usual definitions of addition and multiplication of complex numbers.
    \begin{itemize}
        \item \textbf{Addition-Abelian}: We already proved that $\C$ is a field, so the additive group of $\C$, namely $(\C, +)$, is an abelian group.
        
        \item \textbf{Multiplication-Identity}: Let $a + bi \in \C$. We see $1(a+bi) = 1a + 1bi = a + bi$ so this axiom is satisfied.

        \item \textbf{Multiplication-Compatibility}: Let $p, q \in \R$ and $a + bi \in \C$. Note
        \begin{align*}
            p(q(a+bi)) &= p(qa + qbi)\\
            &= pqa + pqbi\\
            &= (pq)(a+bi)
        \end{align*}
        so this axiom is satisfied.
        
        \item \textbf{Distributivity-Addition}: Let $k \in \R$ and $a + bi, c + di \in \C$. Then
        \begin{align*}
            k((a+bi) + (c+di)) &= k((a+c) + (b+d)i)\\
            &= k(a+c) + k(b+d)i\\
            &= ka + kc + kbi + kdi\\
            &= (ka + kbi) + (kc + kdi)\\
            &= k(a+bi) + k(c+di)
        \end{align*}
        which shows that the axiom is satisfied.
        
        \item \textbf{Distributivity-Scalar}: Let $p, q \in \R$ and $a + bi \in \C$. Note
        \begin{align*}
            (p+q)(a+bi) &= (p+q)a + (p+q)bi\\
            &= pa + qa + pbi + qbi\\
            &= (pa + pbi) + (qa + qbi)\\
            &= p(a+bi) + q(a+bi)
        \end{align*}
        so this axiom is satisfied.
    \end{itemize}
    
    Since all the vector space axioms are satisfied, we proved that $\C$ is a vector space over the field $\R$.
\end{example}

One sees that $\R$ is a subfield of $\C$. The previous example gives us an indication of a much deeper result about vector fields, which we note in the following theorem.

\begin{theorem}\label{thrm-field-is-vector-space}
    Let $F$ be a field and $K$ a subfield of $F$. Then $F$ is a vector space over $K$, with vector addition and scalar multiplication being the operations of $F$.
\end{theorem}
\begin{proof}
    We need to prove the five vector space axioms.
    \begin{itemize}
        \item \textbf{Addition-Abelian}: Since $F$ is a field, therefore $(F, +)$, the additive group of $F$, is an abelian group.
        
        \item \textbf{Multiplication-Identity}: Let $\textbf{u} \in F$. Note $1\textbf{u} = \textbf{u}$ since 1 is the multiplicative identity of $F$, which shows that this axiom is satisfied.

        \item \textbf{Multiplication-Compatibility}: Let $r, s \in K$ and $\textbf{u} \in F$. Then $r(s\textbf{u}) = (rs)\textbf{u}$ by the associativity of multiplication in the field $F$.
        
        \item \textbf{Distributivity-Addition}: Let $k \in K$ and $\textbf{u}, \textbf{v} \in F$. Then $k(\textbf{u} + \textbf{v}) = k\textbf{u} + k\textbf{v}$ by the distributivity of multiplication over addition in the field $F$.
        
        \item \textbf{Distributivity-Scalar}: Let $r, s \in K$ and $\textbf{u} \in \C$. Note that we see $(r+s)\textbf{u} = r\textbf{u} + s\textbf{u}$, again by the distributivity of multiplication over addition in the field $F$.
    \end{itemize}

    Therefore, all five vector space axioms are satisfied, proving that $F$ is a vector space over the subfield $K$.
\end{proof}

\begin{exercise}\label{exercise-R^n-is-abelian-group}
    Prove that $\R^n$ under addition as defined in \myref{example-R^n-is-vector-space} is an abelian group.
\end{exercise}

\begin{exercise}
    Let
    \[
        W = \{f(x) \in \R[x] \vert \deg f(x) = 5\}.
    \]
    Is $W$ a vector space?
\end{exercise}

We note some elementary properties of vectors in vector spaces.
\begin{proposition}\label{prop-vector-scaled-by-zero-is-zero-vector}
    Let $V$ be a vector space over $F$, and let $\textbf{u} \in V$. Then $0\textbf{u} = \textbf{0}$.
\end{proposition}
\begin{proof}
    Note
    \[
        0\textbf{u} = (0 + 0)\textbf{u} = 0\textbf{u} + 0\textbf{u}
    \]
    by \textbf{Distributivity-Scalar}. Then, by adding $-(0\textbf{u})$ on both sides we see
    \begin{align*}
        0\textbf{u} + (-(0\textbf{u})) &= (0\textbf{u} + 0\textbf{u}) + (-(0\textbf{u}))\\
        &= 0\textbf{u} + (0\textbf{u} + (-(0\textbf{u}))) & (\textbf{Addition-Abelian-Associativity})\\
    \end{align*}
    which means
    \[
        \textbf{0} = 0\textbf{u} + \textbf{0},
    \]
    by \textbf{Addition-Abelian-Inverses}, and hence $0\textbf{u} = \textbf{0}$, by \textbf{Addition-Abelian-Identity}.
\end{proof}

\begin{proposition}\label{prop-zero-vector-scaled-by-constant-is-zero-vector}
    Let $V$ be a vector space over $F$, and let $a \in F$. Then $a\textbf{0} = \textbf{0}$.
\end{proposition}
\begin{proof}
    See \myref{exercise-zero-vector-scaled-by-constant-is-zero-vector}.
\end{proof}

\begin{proposition}\label{prop-vector-inverse-is-negative-vector}
    Let $V$ be a vector space over $F$. Let -1 denote the additive inverse of the multiplicative identity of $F$. Let $\textbf{u} \in V$. Then $-\textbf{u} = (-1)\textbf{u}$.
\end{proposition}
\begin{proof}
    One sees that
    \begin{align*}
        \textbf{u} + (-1)\textbf{u} &= 1\textbf{u} + (-1)\textbf{u} & (\textbf{Multiplication-Identity})\\
        &= (1 + (-1))\textbf{u} & (\textbf{Distributivity-Scalar})\\
        &= 0\textbf{u}\\
        &= \textbf{0} & (\myref{prop-vector-scaled-by-zero-is-zero-vector})
    \end{align*}
    which means that $(-1)\textbf{u}$ is the additive inverse of $\textbf{u}$. Since the inverse in a group is unique, therefore \textit{the} additive inverse of $\textbf{u}$ is $(-1)\textbf{u}$, i.e. $-\textbf{u} = (-1)\textbf{u}$.
\end{proof}

\begin{exercise}\label{exercise-zero-vector-scaled-by-constant-is-zero-vector}
    Prove \myref{prop-zero-vector-scaled-by-constant-is-zero-vector}.
\end{exercise}

\section{Subspaces}
Like how groups have subgroups, rings have subrings, and fields have subfields, vector spaces also have their own analogue, called \textbf{subspaces}.
\begin{definition}
    Let $V$ be a vector space over a field $F$ and let $U$ be a subset of $V$. Then $U$ is a \textbf{subspace}\index{subspace} of $V$ if and only if $U$ is also a vector space over $F$ under the operations of $V$.
\end{definition}

\begin{example}
    Since $\R$ is a subset of $\C$ and $\R$ is a vector space over itself, thus $\R$ is a subspace of $\C$.
\end{example}

\begin{example}
    Let $F$ be a field, $K$ a subfield of $F$, and $L$ a subfield of $K$. We note that $F$ is a vector space over $L$ (\myref{thrm-field-is-vector-space}). Also $K$ is a vector space over $L$ using the same reason. Since $K \subseteq F$, thus $K$ is a subspace of $F$.
\end{example}

To prove all the axioms for vector spaces for the subspace is way too tedious. Like with groups, rings, and fields, we have a simple test to determine whether a subset of a vector space is a subspace, called the \textbf{subspace test}.

\begin{theorem}[Subspace Test]\label{thrm-subspace-test}
    Let $V$ be a vector space over a field $F$ and $U$ be a non-empty subset of $V$. Then $U$ is a subspace of $V$ over $F$ and using the same operations as $V$ if and only if
    \begin{itemize}
        \item for any $\textbf{u}, \textbf{v} \in U$ we have $\textbf{u} + \textbf{v} \in U$; and
        \item for any $\textbf{u} \in U$ and $a \in F$ we have $a\textbf{u} \in U$.
    \end{itemize}
\end{theorem}
\begin{proof}
    The forward direction is trivial, since any subspace of $V$ is a vector space, and these two conditions are exactly the closure conditions of addition and scalar multiplication.

    We work in the reverse direction. Suppose these two conditions are satisfied. We will prove the remainder of the vector space axioms.
    \begin{itemize}
        \item \textbf{Addition-Abelian}: Since addition is the same as that of the vector space $V$, addition is also already commutative. So all that remains is to show that $(U, +)$ is a group; we show $(U, +) \leq (V, +)$ instead.
        
        We note that $-1 \in F$ and so $(-1)\textbf{v}$ is in $U$ for any $\textbf{v} \in U$ by condition 2. Note $(-1)\textbf{v} = -\textbf{v}$ by \myref{prop-vector-inverse-is-negative-vector}, so $-\textbf{v} \in U$ for any $\textbf{v} \in U$. Finally, we see
        \[
            \textbf{u} + (-\textbf{v}) \in U
        \]
        by condition 1. Using the subgroup test (\myref{thrm-subgroup-test}) we know $(U, +) \leq (V, +)$.
        
        \item \textbf{Multiplication-Identity}: The axiom holds for $V$, i.e. for all $\textbf{u} \in V$ we have $1\textbf{u} = \textbf{u}$. Since $U \subseteq V$, this means that this statement holds for elements of $U$ too, i.e. for all $\textbf{u} \in U$ we have $1\textbf{u} = \textbf{u}$. Thus this axiom is satisfied.
        
        \item \textbf{Multiplication-Compatibility}: The axiom holds for $V$, so it holds for $U$ since $U \subseteq V$ and by using a similar reasoning as above.
        
        \item \textbf{Distributivity-Addition}: The axiom holds for $V$, so it holds for $U$ by using a similar reasoning as above.
        
        \item \textbf{Distributivity-Scalar}: The axiom holds for $V$, so it holds for $U$ by using a similar reasoning as above.
    \end{itemize}
    So all the vector space axioms are satisfied, meaning that $U$ is a vector space over $F$. As $U \subseteq V$, we therefore see that $U$ is a subspace of $V$.
\end{proof}
\begin{remark}
    Like with the subgroup test, we usually verify $U$ is non-empty by asserting that the zero vector is inside $U$.
\end{remark}

\begin{example}
    We prove that $\R$ is a subspace of $\C$ over $\R$ by considering the subspace test (\myref{thrm-subspace-test}).
    \begin{itemize}
        \item We note that the zero vector of $\C$, 0, is also present in $\R$, so $\R$ is non-empty.
        \item Also note that for any real numbers $\textbf{x}$ and $\textbf{y}$ we have $\textbf{x} + \textbf{y} \in \R$.
        \item Finally, the product of any two real numbers is real, so for $a \in \R$ and $\textbf{u} \in \R$ we have $a\textbf{u} \in \R$.
    \end{itemize}
    Thus $\R$ is a subspace of $\C$ over $\R$.
\end{example}

Admittedly, the previous example is quite boring. Let's look at a more interesting example.
\begin{example}
    We know that $\R^4$ is a vector space over $\R$ (\myref{example-R^n-is-vector-space}). Consider the set
    \[
        V = \{(a, b, a-b, a+b) \vert a, b \in \R\}.
    \]
    We show that $V$ is a subspace of $\R^4$ over $\R$.
    \begin{itemize}
        \item Note that the zero vector of $\R^4$, $(0,0,0,0)$, is in $V$ by choosing $a = b = 0$. Therefore $V$ is non-empty.
        \item For any two vectors $\textbf{u} = (a, b, a-b, a+b)$ and $\textbf{v} = (c, d, c-d, c+d)$ in $V$, we see
        \begin{align*}
            \textbf{u} + \textbf{v} &= (a, b, a-b, a+b) + (c, d, c-d, c+d)\\
            &= (a + c, b + d, a - b + c - d, a + b + c + d)\\
            &= (a+c, b+d, (a+c)-(b+d), (a+c)+(b+d))\\
            &\in V.
        \end{align*}
        \item For $\alpha \in \R$ and $\textbf{u} = (a, b, a-b, a+b) \in V$ we note
        \begin{align*}
            \alpha\textbf{u} &= \alpha(a, b, a-b, a+b)\\
            &= (\alpha a, \alpha b, \alpha(a-b), \alpha(a+b))\\
            &= (\alpha a, \alpha b, (\alpha a) - (\alpha b), (\alpha a) + (\alpha b))\\
            &\in V.
        \end{align*}
    \end{itemize}
    Therefore $V$ is a subspace of $\R^4$ by the subspace test (\myref{thrm-subspace-test}).
\end{example}

\begin{exercise}
    Let $F$ be a field and $n$ be a non-negative integer. Prove that
    \[
        V = \{f(x) \in F[x] \vert \deg f(x) \leq n\} \cup \{0\}
    \]
    is a vector space over $F$ using the definitions of polynomial addition and scalar multiplication.\newline
    (\textit{Note: be careful with the zero polynomial!})
\end{exercise}

\section{Linear Combinations and Span}
Vector spaces have many elements. Using the vector space axioms, we may express these elements in terms of other elements from the vector space. One may wonder if there is a set of elements that `generates' the full vector space. This is the motivation for the \textbf{spanning set} of a vector space.

Before that, let's define what a linear combination is.
\begin{definition}
    Let $\textbf{v}_1, \textbf{v}_2, \dots, \textbf{v}_n$ be vectors belonging to a vector space $V$ over a field $F$. A vector $\textbf{u} \in V$ is said to be a \textbf{linear combination}\index{linear combination} of the vectors $\textbf{v}_1, \textbf{v}_2, \dots, \textbf{v}_n$ if
    \[
        \textbf{u} = \alpha_1\textbf{v}_1 + \alpha_2\textbf{v}_2 + \cdots + \alpha_n \textbf{v}_n
    \]
    where $\alpha_1, \alpha_2, \dots, \alpha_n \in F$.
\end{definition}

\begin{definition}
    Let $V$ be a vector space over a field $F$ and let $S$ be a subset of $V$. Then the \textbf{span}\index{span} of $S$ is denoted $\Span{S}$ and is the set of all linear combinations of the vectors of $S$. In other words, if $S = \{\textbf{v}_1, \textbf{v}_2, \dots, \textbf{v}_n\}$ then
    \[
        \Span{S} = \left\{\sum_{i=1}^n \alpha_i\textbf{v}_i \vert \alpha_i \in F\right\}.
    \]
\end{definition}
\begin{remark}
    \cite[p.~331]{gallian_2016} uses the alternate notation $\left\langle\textbf{v}_1, \textbf{v}_2, \dots, \textbf{v}_n\right\rangle$, while \cite[p.~31]{treil_2017} uses the notation $\mathcal{L}\left(\textbf{v}_1, \textbf{v}_2, \dots, \textbf{v}_n\right)$.
\end{remark}

\begin{definition}
    Let $V$ be a vector space over a field $F$ and let $S$ be a subset of $V$. Then $S$ is called a \textbf{spanning set}\index{spanning set} of $V$ if and only if $\Span{S} = V$, and we say that $S$ \textbf{spans} $V$.
\end{definition}

\begin{example}
    It is quite obvious that $\{(1, 0, 0), (0, 1, 0), (0, 0, 1)\} \subset \R^R$ spans $\R^3$.
\end{example}

\begin{example}
    Consider the set $S = \{(1, 2, 1), (1, 0, 2), (1, 1, 0)\} \subset \R^3$. We show that $S$ spans $V$.

    Let $(a, b, c) \in \R^3$. Consider $\alpha_1(1, 2, 1) + \alpha_2(1, 0, 2) + \alpha_3(1, 1, 0) = (a, b, c)$. Thus we see
    \begin{align*}
        \alpha_1 + \alpha_2 + \alpha_3 &= a\\
        2\alpha_2  + \alpha_3 &= b\\
        \alpha_1 + 2\alpha_2 &= c 
    \end{align*}
    which we may solve to get
    \begin{align*}
        \alpha_1 &= \frac13(c + 2b - 2a)\\
        \alpha_2 &= \frac13(c - b + a)\\
        \alpha_3 &= \frac13(4a - b - 2c)
    \end{align*}
    which means that each element in $\R^3$ has a unique set of $\alpha_1, \alpha_2, \alpha_3 \in \R$ that produces it. Therefore $\Span{S} = \R^3$.
\end{example}

\begin{example}
    We show that $(-3, 1)$ does not lie in $\Span{(1,1), (2,2)}$.

    Suppose otherwise, that $\alpha(1,1) + \beta(2,2) = (-3,1)$ for some $\alpha, \beta \in \R$. Then
    \begin{align*}
        \alpha + 2\beta = -3\\
        \alpha + 2\beta = 1
    \end{align*}
    which clearly has no solution. Therefore $(-3, 1) \notin \Span{(1, 1), (2, 2)}$.
\end{example}

\begin{example}
    Let the vector space
    \[
        V = \{f(x) \in \R[x] \vert \deg f(x) \leq 2\} \cup \{0\}.
    \]
    Let $S = \{x^2 + 2, x^2 + 2x + 1\}$. We show that $S$ is not a spanning set of $V$.

    Consider the constant polynomial 1. Suppose that 1 can be expressed as a linear combination of the polynomials in $S$, i.e. $\alpha(x^2 + 2) + \beta(x^2+2x+1) = 1$ for some $\alpha, \beta \in \R$, i.e. $(\alpha + \beta)x^2 + 2\beta x + (2\alpha + \beta) = 1$. So we see
    \begin{align*}
        \alpha + \beta = 0\\
        2\beta = 0\\
        2\alpha + \beta = 1
    \end{align*}
    which has no solution. Therefore $1 \notin \Span{S}$, meaning that $\Span{S} \neq V$.
\end{example}

\begin{exercise}
    Let the vector space
    \[
        V = \{f(x) \in \Q[x] \vert \deg f(x) \leq 2\} \cup \{0\}.
    \]
    Let $S = \{x, x + 2, x^2 + 2, x^2 + 2x + 3\}$. Prove or disprove: $S$ is a spanning set for $V$.
\end{exercise}

\newpage

\section{Linear (In)dependence and Basis}
% TODO: Add

\newpage

\section{Problems}
% TODO: Add
