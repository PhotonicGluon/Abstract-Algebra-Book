\chapter{Polynomial Rings and Division}
Polynomial rings are an important part of algebra and in ring theory, since polynomials are ubiquitous in modern algebra. We explore polynomials and polynomial rings in this chapter.

\section{What is a Polynomial Ring?}
One of the most familiar concepts that one encounters in algebra are polynomials.

\begin{definition}
    A \textbf{polynomial}\index{polynomial} is an expression consisting of \textbf{variables}\index{polynomial!variable} (or \textbf{indeterminates}\index{polynomial!indeterminate}) and coefficients, that involves only the operations of addition, subtraction, multiplication, and positive-integer powers of variables.
\end{definition}
\begin{definition}
    Polynomials in a single variable are called \textbf{univariate polynomials}\index{polynomial!univariate} and takes the form
    \[
        a_0+a_1x+a_2x^2+\cdots+a_nx^n = \sum_{i=0}^n a_ix^i,
    \]
    where $a_0, a_1, a_2, \dots, a_n$ are called the \textbf{coefficients}\index{polynomial!coefficient} of the polynomial.
\end{definition}

We are most familiar with polynomials with integer coefficients, rational coefficients, and real coefficients. We abstract the idea of coefficients to those belonging in a ring.

\begin{definition}
    Let $R$ be a commutative ring. The set
    \[
        R[x] = \left\{\sum_{i=0}^n a_ix^i \vert n \in \mathbb{N} \cup \{0\}, \; a_i \in R\right\},
    \]
    read ``R adjoin $x$'', is called the \textbf{ring of polynomials over $R$}\index{polynomial ring} in the \textbf{indeterminate}\index{indeterminate} (or \textbf{variable}\index{variable}) $x$.
\end{definition}

One must take care to disambiguate between the polynomial and the \textit{function} determined by the polynomial.
\begin{example}
    Consider the polynomial ring $\Z_3[x]$, and the polynomials $f(x) = x$ and $g(x) = x^3$. We note that $f(x)$ and $g(x)$ are \textit{distinct} elements of $\Z_3[x]$. However, we note that
    \begin{align*}
        f(0) &= 0 = g(0),\\
        f(1) &= 1 = g(1), \text{ and }\\
        f(2) &= 2 = 8 = 2^3 = g(2)
    \end{align*}
    in $\Z_3$, so these two functions are equal.
\end{example}

Note that, in general, the expression $f(a)$ for an $a \in R$ means to substitute $a$ for $x$ in the formula for $f(x)$. We leave proving that this is actually a ring homomorphism for \myref{exercise-polynomial-evaluation-is-ring-homomorphism} (later).

To make $R[x]$ into a ring, we need to define addition and multiplication on that set.
\begin{definition}
    Let $R$ be a commutative ring. Let
    \begin{gather*}
        f(x) = a_0 + \cdots + a_mx^m\\
        g(x) = b_0 + \cdots + b_nx^n
    \end{gather*}
    be polynomials in $R[x]$. Let $s$ be the maximum of $m$ and $n$, and define $a_i = 0$ for $i > m$ and $b_i = 0$ for $i > n$. Then \textbf{polynomial addition}\index{polynomial!addition} is defined to be
    \[
        f(x)+g(x) = \sum_{i=0}^s\left((a_i+b_i)x^i\right)
    \]
    and \textbf{polynomial multiplication}\index{polynomial!multiplication} is defined to be
    \[
        f(x)g(x) = \sum_{i=0}^{m+n}c_ix^i
    \]
    where
    \[
        c_k = \sum_{i=0}^k a_ib_{k-i}
    \]
    for all $0 \leq k \leq m + n$.
\end{definition}
Although this definition of multiplication of polynomials may seem complicated, this is just a formalization of the usual process of using the distributive axiom of real numbers (\myref{axiom-distributivity}) and collecting like terms. So multiplying polynomials over a commutative ring $R$ is the same as how polynomials are always multiplied.

\begin{proposition}
    $R[x]$ is a commutative ring under polynomial addition and multiplication.
\end{proposition}
\begin{proof}
    We first prove that $R[x]$ is indeed a ring, before proving commutativity of multiplication of polynomials. For brevity, let $f(x)$, $g(x)$, and $h(x)$ be polynomials in the set $R[x]$ such that
    \begin{align*}
        f(x) &= a_0 + a_1x + a_2x^2 + \cdots + a_mx^m,\\
        g(x) &= b_0 + b_1x + b_2x^2 + \cdots + b_nx^n,\\
        h(x) &= c_0 + c_1x + c_2x^2 + \cdots + c_lx^l,
    \end{align*}
    each $a_i$, $b_j$, and $c_k$ are elements from $R$, the integers $m$, $n$, and $l$ are all non-negative, and $a_m$, $b_n$, and $c_l$ are all non-zero. Without loss of generality, assume $m \geq n \geq l$, let $b_i = 0$ for $i > n$, and let $c_i = 0$ for $i > l$. This still results in the argument being general as we will later show that both addition and multiplication in the polynomial ring are commutative.
    \begin{itemize}
        \item \textbf{Addition-Abelian}: We show that $(R[x], +)$ is an abelian group.
        \begin{itemize}
            \item \textbf{Closure}: We see
            \[
                f(x) + g(x) = \sum_{i=0}^n\left((a_i+b_i)x^i\right)
            \]
            and since $R$ is a ring, thus $a_i+b_i \in R$, meaning $f(x) + g(x)$ is another polynomial in $R[x]$. Therefore $R[x]$ is closed under addition.
            
            \item \textbf{Associativity}: Note
            \begin{align*}
                f(x) + (g(x) + h(x)) &= f(x) + \sum_{i=0}^m\left((b_i+c_i)x^i\right)\\
                &= \sum_{i=0}^m\left((a_i + (b_i + c_i))x^i\right)\\
                &= \sum_{i=0}^m\left(((a_i + b_i) + c_i)x^i\right) & (+ \text{ is associative in }R)\\
                &= \sum_{i=0}^m\left((a_i+b_i)x^i\right) + h(x)\\
                &= (f(x) + g(x)) + h(x)
            \end{align*}
            so addition of functions is associative.
            
            \item \textbf{Identity}: Note that $0 \in R$ is also the identity in $R[x]$, since
            \[
                0 + f(x) = \sum_{i=0}^m\left((0+a_i)x^i\right) = \sum_{i=0}^m\left(a_ix^i\right) = f(x).
            \]
            
            \item \textbf{Inverse}: For the polynomial $f(x)$, let
            \[
                -f(x) = \sum_{i=0}^m(-a_i)x^i.
            \]
            Then
            \[
                f(x) + (-f(x)) = \sum_{i=0}^m\left((a_i+(-a_i))x^i\right) \sum_{i=0}^m\left(0x^i\right) = 0
           \]
           so $-f(x)$ is indeed the additive inverse of $f(x)$.
            
            \item \textbf{Commutativity}: One sees clearly that
            \[
                f(x) + g(x) = \sum_{i=0}^m\left((a_i+b_i)x^i\right) = \sum_{i=0}^m\left((b_i + a_i)x^i\right) = g(x) + f(x)
            \]
            since addition in $R$ is commutative. Therefore addition in $R[x]$ is also commutative.
        \end{itemize}

        \item \textbf{Multiplication-Subgroup}: We show that $(R[x], \times)$ is a subgroup.
        \begin{itemize}
            \item \textbf{Closure}: We note that
            \[
                c_k = \sum_{i=0}^k a_ib_{k-i}
            \]
            is an element of $R$, so
            \[
                f(x)g(x) = \sum_{k=0}^{m+n}c_kx^k
            \]
            is another polynomial in $R[x]$.
            
            \item \textbf{Associativity}: \myref{exercise-polynomial-multiplication-is-associative} (later) proves that polynomial multiplication is associative.
        \end{itemize}

        \item \textbf{Distributive}: We finally show that $\times$ distributes over $+$. We only show that $f(x)(g(x) + h(x)) = f(x)g(x) + f(x)h(x)$ as we will later prove that $R[x]$ is commutative. Note
        \begin{align*}
            f(x)(g(x) + h(x)) &= \sum_{i=0}^m\left(\left(\sum_{j=0}^ia_j(b_{i-j}+c_{i-j})\right)x^i\right)\\
            &= \sum_{i=0}^m\left(\left(\sum_{j=0}^i(a_jb_{i-j}+a_jc_{i-j})\right)x^i\right) & (\text{Distribute in }R)\\
            &= \sum_{i=0}^m\left(\sum_{j=0}^i(a_jb_{i-j}x^i+a_jc_{i-j}x^i)\right)\\
            &= \sum_{i=0}^m\left(\sum_{j=0}^ia_jb_{i-j}x^i + \sum_{j=0}^ia_jc_{i-j}x^i\right)\\
            &= \sum_{i=0}^m\left(\sum_{j=0}^ia_jb_{i-j}x^i\right) + \sum_{i=0}^m\left(\sum_{j=0}^ia_jc_{i-j}x^i\right)\\
            &= f(x)g(x) + f(x)h(x)
        \end{align*}
        which is what was needed to be shown.
    \end{itemize}
    Therefore $R[x]$ is a ring.

    Now we prove commutativity of multiplication. Let $f(x) = a_0 + \cdots + a_mx^m, g(x) = b_0 + \cdots + b_nx^n \in R[x]$, and $m \leq n$. Then
    \begin{align*}
        f(x)g(x) &= \sum_{k=0}^{m+n}\left(\left(\sum_{i=0}^k a_ib_{k-i}\right)x^k\right)\\
        &= \sum_{k=0}^{m+n}\left(\left(\sum_{i=0}^k b_{k-i}a_i\right)x^k\right) & (R\text{ is commutative})\\
        &= \sum_{k=0}^{m+n}\left(\left(\sum_{i=0}^k b_i a_{k-i}\right)x^k\right)\\
        &= g(x)f(x)
    \end{align*}
    which therefore means that $R[x]$ is a commutative ring.
\end{proof}

Let's look at some examples of polynomial rings.
\begin{example}
    The polynomial ring $\R[x]$ is the most familiar for most of us, as this is the `standard' ring of polynomials. Examples of polynomials in this ring include $1+x$, $\sqrt2x^{10} - 5x^3 + \pi x$, and $1+x+x^2+\cdots+x^n$. However, infinite polynomials such as $1+x+x^2+\cdots$ do not belong in $\R[x]$.
\end{example}
\begin{example}
    Another commonly used polynomial ring is $\Q[x]$. Examples of polynomials in this ring are $1+x$, $\frac23x^5 - \frac7{11}x^{13}$, and $2x^2-5x-3$. However polynomials like $\sqrt2$, $\pi x + 1$, and $1+ex$ do not belong in $\Q[x]$.
\end{example}
\begin{example}
    We look at the polynomial ring $\Mn{2}{\R}[x]$. One example of a polynomial in this ring is
    \[
        \begin{pmatrix}2&1\\-2&0\end{pmatrix} + \begin{pmatrix}\sqrt2&1\\1&1\end{pmatrix}x + \begin{pmatrix}5&4\\e&2\end{pmatrix}x^2 + \begin{pmatrix}0&1\\0&0\end{pmatrix}x^5.
    \]
\end{example}

We now look at an example of polynomial addition and multiplication.
\begin{example}
    Consider the polynomial ring $\Z_3[x]$, and the polynomials $f(x) = x^2 + 2x + 2$ and $g(x) = 2x^2 + 2x + 1$. Then
    \begin{align*}
        f(x) + g(x) &= (1+2)x^2 + (2+2)x + (2+1)\\
        &= 3x^2 + 4x + 3\\
        &= 0x^2 + x + 0 & (\text{Coefficients are written in }\Z_3)\\
        &= x
    \end{align*}
    and
    \begin{align*}
        f(x)g(x) &= (x^2+2x+2)(2x^2+2x+1)\\
        &= 2x^4 + 6x^3 + 9x^2 + 6x + 2\\
        &= 2x^4 + 0x^3 + 0x^2 + 0x + 2 & (\text{Coefficients are written in }\Z_3)\\
        &= 2x^4 + 2.
    \end{align*}
    Note that there are equivalent functions to $f(x)+g(x)$ and $f(x)g(x)$. Let $A(x) = x^3$ and $B(x) = 2-x^2$. When iterating through all values in $\Z_3$, we generate the following table.
    \begin{table}[H]
        \centering
        \begin{tabular}{|l|l|l|l|l|}
            \hline
            $\boldsymbol{x}$ & $\boldsymbol{f(x)+g(x)}$ & $\boldsymbol{A(x)}$ & $\boldsymbol{f(x)g(x)}$ & $\boldsymbol{B(x)}$ \\ \hline
            \textbf{0} & 0 & 0 & 2 & 2 \\ \hline
            \textbf{1} & 1 & 1 & 1 & 1 \\ \hline
            \textbf{2} & 2 & 2 & 1 & 1 \\ \hline
        \end{tabular}
    \end{table}
    Thus, we see that $f(x)+g(x) = A(x)$ and $f(x)g(x) = B(x)$ as functions, even though they are distinct as polynomials.
\end{example}

\begin{exercise}\label{exercise-polynomial-evaluation-is-ring-homomorphism}
    Let $R$ be a commutative ring. The \textbf{evaluation homomorphism}\index{evaluation homomorphism} is $\phi_a: R[x] \to R$ where $\phi_a(p(x)) = p(a)$ and $a \in R$. Prove that $\phi_a$ is indeed a ring homomorphism.
\end{exercise}
\begin{exercise}\label{exercise-polynomial-multiplication-is-associative}
    Prove that polynomial multiplication is associative.\newline
    (\textit{Hint: $\displaystyle c_k = \sum_{i+j=k} a_ib_j$, which is the sum over all non-negative integers $i$ and $j$ with the property that $i+j=k$.})
\end{exercise}

We end this section by noting what form $R[x]$ takes when $x$ is \textit{not} a variable.
\begin{example}
    Recall that $\Q[\sqrt2] = \{a + b\sqrt2 \vert a,b \in \Q\}$. If we use the definition of $\Q[x]$, and `substitute' $x$ with $\sqrt2$, we see that
    \begin{align*}
        &\Q[\sqrt2] \\
        &= \{a_0 + a_1\sqrt2 + a_2(\sqrt2)^2 + a_3(\sqrt2)^3 + \cdots + a_n(\sqrt2)^n \vert a_i \in \Q \}\\
        &= \{a_0 + a_1\sqrt2 + a_2(2) + a_3(2\sqrt2) + \cdots + a_n(\sqrt2)^n \vert a_i \in \Q \}\\
        &= \{(a_0 + 2a_2 + 4a_4 + \cdots) + \sqrt2 (a_1 + 2a_3 + 4a_5 + \cdots) \vert a_i \in \Q\}\\
        &= \{a + b\sqrt2 \vert a,b \in Q\}
    \end{align*}
    which agrees with the previous definition of $\Q[\sqrt2]$.
\end{example}
\begin{example}
    Recall that $\Z[i]$, the gaussian integers, is the set $\{a+bi \vert a,b \in \Z\}$. If we use the definition of $\Z[x]$ and `substitute' $x$ with $i$ we see that
    \begin{align*}
        \Z[i] &= \{a_0 + a_1i + a_2i^2 + a_3i^3 + \cdots + a_ni^n \vert a_i \in \Z\}\\
        &= \{a_0 + a_1i + a_2(-1) + a_3(-i) + \cdots + a_ni^n \vert a_i \in \Z\}\\
        &= \{(a_0 - a_2 + a_4 - \cdots) + i(a_1 - a_3 + a_5 - \cdots) \vert a_i \in \Z\}\\
        &= \{a + bi \vert a,b \in \Z\}
    \end{align*}
    which agrees with the previous definition of $\Z[i]$.
\end{example}

\begin{exercise}
    Show that $\Q[\sqrt[3]{2}] = \left\{a + b\sqrt[3]{2} + c\sqrt[3]4 \vert a,b,c \in \Q\right\}$.
\end{exercise}

\section{Polynomial Terminology}
\begin{definition}
    Let $R[x]$ be a polynomial ring. The \textbf{degree}\index{degree} of a polynomial $f(x) \in R[x]$, denoted $\deg f(x)$, is the largest integer $k$ such that the coefficient of $x^k$ of $f(x)$ is non-zero.
\end{definition}
\begin{remark}
    For the zero polynomial (0), the degree is undefined.
\end{remark}
\begin{example}
    The degree of the polynomial $1+x+5x^2$ in $\Z[x]$ is 2.
\end{example}
\begin{example}
    The degree of the polynomial
    \[
        \begin{pmatrix}0&1\\3&0\end{pmatrix}x^5 + \begin{pmatrix}3&6\\7&2\end{pmatrix}x^4 + \begin{pmatrix}3&4\\9&4\end{pmatrix}
    \]
    in $\Mn{2}{\Z}[x]$ is 5.
\end{example}
\begin{exercise}
    Give an example of a degree 5 polynomial in the ring $\Z_2[x]$.
\end{exercise}

\begin{definition}
    Let $f(x) = a_0 + a_1x + a_2x^2 + \cdots + a_nx^n$ be a polynomial in the polynomial ring $R[x]$.
    \begin{itemize}
        \item The \textbf{constant term}\index{constant term} is $a_0$.
        \item The \textbf{leading term}\index{leading term} is the term $a_nx^n$.
        \item The \textbf{leading coefficient}\index{leading coefficient} is $a_n$.
    \end{itemize}
\end{definition}
\begin{remark}
    For the zero polynomial, the constant term is 0, the leading term is undefined, and the leading coefficient is undefined.
\end{remark}
\begin{example}
    Consider the polynomial
    \[
        \begin{pmatrix}0&1\\3&0\end{pmatrix}x^5 + \begin{pmatrix}3&6\\7&2\end{pmatrix}x^4 + \begin{pmatrix}3&4\\9&4\end{pmatrix}
    \]
    in $\Mn{2}{\Z}[x]$. Then
    \begin{itemize}
        \item the constant term is $\begin{pmatrix}3&4\\9&4\end{pmatrix}$;
        \item the leading term is $\begin{pmatrix}0&1\\3&0\end{pmatrix}x^5$; and
        \item the leading coefficient is $\begin{pmatrix}0&1\\3&0\end{pmatrix}$.
    \end{itemize}
\end{example}

\begin{definition}
    A \textbf{constant polynomial}\index{constant polynomial} is either the zero polynomial of a polynomial of degree 0.
\end{definition}
\begin{proposition}
    For a commutative ring $R$,
    \begin{itemize}
        \item a constant polynomial in $R[x]$ is an element of $R$,
        \item an element of $R$ is a constant polynomial of $R[x]$.
    \end{itemize}
\end{proposition}
\begin{proof}
    See \myref{exercise-constant-polynomial-iff-ring-element} (later).
\end{proof}
\begin{example}
    Both 0 and 2 are constant polynomials in $\Z[x]$. However $x + 1$ and $x^2 + x + 1$ are not constant polynomials in $\Z[x]$.
\end{example}
\begin{example}
    $\frac{12}{34}$ is a constant polynomial in $\Q[x]$, $\R[x]$, and $\C[x]$.
\end{example}

\begin{definition}
    A \textbf{root}\index{polynomial!roots} (or \textbf{zero}\index{polynomial!zeroes}) of a polynomial $f(x)$ in the polynomial ring $R[x]$ is an $r \in R$ such that $f(r) = 0$ in $R$.
\end{definition}
\begin{example}
    The zeroes of $f(x) = x^2+7$ in $\Z_8[x]$ are 1, 3, 5, and 7, since
    \begin{align*}
        f(1) &= 1^2 + 7 = 8 = 0,\\
        f(3) &= 3^2 + 7 = 16 = 0,\\
        f(5) &= 5^2 + 7 = 32 = 0, \text{ and}\\
        f(7) &= 7^2 + 7 = 56 = 0
    \end{align*}
    in $\Z_8$.
\end{example}
\begin{example}
    The zeroes of the zero polynomial in a polynomial ring $R[x]$ is the entirety of the ring $R$, since it always equals 0.
\end{example}

\begin{exercise}
    Find the zeroes of the polynomial $x^2-1$ in $\Z_4[x]$.
\end{exercise}
\begin{exercise}\label{exercise-constant-polynomial-iff-ring-element}
    Let $R$ be a commutative ring.
    \begin{partquestions}{\alph*}
        \item Show that any element in $R$ is a constant polynomial of $R[x]$.
        \item If $f(x)$ is a constant polynomial in $R[x]$, show that $f(x) \in R$.
    \end{partquestions}
\end{exercise}

\section{Properties of Polynomials and Polynomial Rings}
We can now state the theorem that produces a condition for a ring to be an integral domain.
\begin{theorem}\label{thrm-integral-domain-iff-polynomial-ring-is-also}
    Let $R$ be a ring. Then $R$ is an integral domain if and only if $R[x]$ is an integral domain.
\end{theorem}
\begin{proof}
    We first need to show that $R$ is a commutative ring with identity if and only if $R[x]$ is a commutative ring with identity. We leave this for \myref{exercise-commutative-ring-with-identity-iff-polynomial-ring-is-also} (later). We only prove that $R$ has no zero divisors if and only if $R[x]$ has no zero divisors using a contrapositive proof.

    For the forward direction, take non-zero $a$ and $b$ in $R$ such that $ab = 0$. We may view both $a$ and $b$ as degree 0 polynomials in $R[x]$. Clearly these two multiply together to form the zero polynomial in $R[x]$, meaning that they are zero divisors in $R[x]$.

    For the reverse direction, take non-zero polynomials $f(x)$ and $g(x)$ in $R[x]$ such that $f(x)g(x) = 0$. Write
    \begin{align*}
        f(x) = a_0+a_1x+a_2x^2+\cdots+a_mx^m \text{ with } a_m \neq 0\\
        g(x) = b_0+b_1x+b_2x^2+\cdots+b_nx^n \text{ with } b_n \neq 0
    \end{align*}
    where all coefficients are in $R$. Multiplying them together yields something like
    \[
        a_mb_nx^{m+n} + (\text{A polynomial with degree less than }m+n) = 0
    \]
    which hence means that all coefficients must be zero. Therefore $a_mb_n = 0$. This means that we have found non-zero elements $a_m$ and $b_n$ in $R$ such that their product is zero, meaning that they are zero divisors.

    This completes the proof.
\end{proof}
\begin{exercise}\label{exercise-commutative-ring-with-identity-iff-polynomial-ring-is-also}
    Let $R$ be a ring.
    \begin{partquestions}{\alph*}
        \item Prove that $R$ is a ring with identity if and only if $R[x]$ is a ring with identity.
        \item Prove that $R$ is a commutative ring if and only if $R[x]$ is a commutative ring.
    \end{partquestions}
\end{exercise}

\newpage

\section{Problems}
\begin{problem}
    Let $I$ be a principal ideal of $\Z[x]$ generated by the polynomial $x^2 + 3x - 1$. Simplify $\left((x + 3) + I\right)\left((2x^2 + 3x - 1) + I\right)$ in the quotient ring $\Z[x]/I$.
\end{problem}

\begin{problem}
    Show that $\princ{x}$ is a prime ideal in $\Z[x]$.
\end{problem}

\begin{problem}
    Let $I = \{f(x) \in \Z[x] \vert f(-2) = 0\}$ be a subset of $\Z[x]$, and let the map $\phi:\Z[x]\to\Z, f(x) \mapsto f(-2)$.
    \begin{partquestions}{\roman*}
        \item Show that $\phi$ is a ring homomorphism.
        \item Show that $I$ is an ideal of $\Z[x]$.
        \item Hence determine if the ideal $I$ is prime, maximal, or both.
    \end{partquestions}
\end{problem}

\begin{problem}
    Prove that $\Z[x] / \princ{x} \cong \Z$.
\end{problem}
