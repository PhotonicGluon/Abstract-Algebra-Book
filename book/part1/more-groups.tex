\chapter{More Types of Groups}
We previously introduced some types of groups, like the cyclic groups, the dihedral groups, and the Klein-four group. We now introduce more types of groups to expand our knowledge of the types of groups that are involved in group theory.

\section{More About Cyclic Groups}\label{section-more-about-cyclic-groups}
We previously covered several properties of cyclic groups.
\begin{itemize}
    \item Every cyclic group is abelian. (\myref{prop-cyclic-group-is-abelian})
    \item A finite group $G$ is cyclic if and only if there exists an element $g \in G$ with the same order as the group. (\myref{thrm-cyclic-group-has-element-with-same-order})
    \item If $G$ is cyclic and $H$ is a subgroup of $G$ then $G/H$ is cyclic. (\myref{exercise-quotient-group-of-cyclic-group-is-cyclic})
    \item Any subgroup of a cyclic group is cyclic. (\myref{problem-subgroup-of-cyclic-group-is-cyclic})
    \item $\Z / (n\Z) \cong \Z_n$. (\myref{problem-Zn-isomorphic-to-Z-by-nZ})
    \item $\Z_m \times \Z_n \cong \Z_{mn}$ if and only if $\gcd(m,n) = 1$. (\myref{thrm-Zm-cross-Zn-isomorphic-to-Zmn-condition})
    \item $m\Z / n\Z \cong \Z_{\frac nm}$. (\myref{problem-mZ/nZ-isomorphic-to-Zn/m})
\end{itemize}

\begin{exercise}\label{exercise-Zmn-mod-Zn-cong-Zn}
    Prove that
    \[
        \Z_{mn} / \Z_m \cong \Z_n
    \]
    for any positive integers $m$ and $n$.
\end{exercise}

Note that we may denote the finite cyclic group of order $n$ by $\Cn{n}$ instead of $\Z_n$. This may be sometimes used to distinguish (finite) cyclic subgroups of a group from the integers modulo $n$.

\newpage

\begin{theorem}\label{thrm-order-of-element-in-cyclic-group}
    Let $\Cn{n}$ have generator $g$. Let $x = g^k$ for some integer $k$. Then
    \[
        |x| = \frac{n}{\gcd(k,n)}.
    \]
\end{theorem}
\begin{proof}
    Direct application of \myref{thrm-order-of-power-of-element}.
\end{proof}

\begin{exercise}
    The number 12 is equivalent to 0 in the group $\Z_n$. What are the possible value(s) of $n$?
\end{exercise}
\begin{exercise}
    In the group $\Z_{210}$, find the order of 10, 42, 75, and 140.
\end{exercise}

\begin{corollary}\label{corollary-element-in-cyclic-group-is-generator-iff-gcd-is-1}
    Let $\Cn{n}$ have generator $g$. Then $g^m$ is also a generator if and only if $\gcd(m, n) = 1$.
\end{corollary}
\begin{proof}
    We prove the forward direction first. Suppose that $\Cn{n}$ has a generator of $g^m$. On one hand, we see $|g^m| = n$ since a generator of a group necessarily has to have an order equal to that of the group. On another hand, by \myref{thrm-order-of-element-in-cyclic-group}, we have $|g^m| = \frac{n}{\gcd(m, n)}$. Hence, we see $n = \frac{n}{\gcd(m, n)}$ which quickly implies $\gcd(m, n) = 1$.

    Now we prove the reverse direction. Suppose $\gcd(m,n) = 1$. Then $|g^m| = \frac{n}{\gcd(m,n)} = \frac{n}{1} = n$ by \myref{thrm-order-of-element-in-cyclic-group}. Hence $g^m$ is a generator of $\Cn{n}$ by \myref{thrm-cyclic-group-has-element-with-same-order}.
\end{proof}

\begin{exercise}
    Find all the generators of the following groups.
    \begin{partquestions}{\alph*}
        \item $\Z_{10}$
        \item $\Z_{101}$
    \end{partquestions}
\end{exercise}

\section{The Quaternion Group}
We look at an interesting group that has use in computer graphics: the quaternion group. We present one definition here.

\newpage

\begin{definition}\label{definition-quaternion-group}
    The \term{quaternion group}\index{quaternion group} is
    \[
            \mathrm{Q} = \{1, -1, i, -i, j, -j, k, -k\}
    \]
    where
    \begin{multicols}{2}
        \begin{itemize}
            \item 1 is the identity;
            \item $(-1)^2 = 1$;
            \item $i^2 = j^2 = k^2 = -1$;
            \item $ij = k$ and $ji = -k$;
            \item $jk = i$ and $kj = -i$; and
            \item $ki = j$ and $ik = -j$.
        \end{itemize}
    \end{multicols}
\end{definition}

The quaternion group has 4 proper non-trivial subgroups, namely $\langle -1 \rangle = \{\pm1\}$, $\langle i \rangle = \{\pm1, \pm i\}$, $\langle j \rangle = \{\pm1, \pm j\}$, and $\langle k \rangle = \{\pm1, \pm k\}$.

With these subgroups, we can write a presentation for $\mathrm{Q}$.
\begin{proposition}
    $\mathrm{Q} = \langle i, j \rangle$.
\end{proposition}
\begin{proof}
    For brevity let $G = \langle i, j \rangle$. We note that $i^0 = 1$, $i^4 = j^4 = 1$ and $ji = -k = -ij = i^3j$. Hence,
    \begin{align*}
        G &= \{1, i, i^2, i^3, j, ij, i^2j, i^3j\}\\
        &= \{1, i, -1, -i, j, ij, -j, -ij\}\\
        &= \{1, -1, i, -i, j, -j, ij, -ij\} & (\text{reordering})\\
        &= \{1, -1, i, -i, j, -j, k, -k\} & (\text{since } ij = k)\\
        &= \mathrm{Q}
    \end{align*}
    so $\mathrm{Q} = \langle i, j \rangle$.
\end{proof}

Thus, an alternate definition of $\mathrm{Q}$ is
\[
    \mathrm{Q} = \langle \alpha, \beta \vert \alpha^4 = e,\; \alpha^2 = \beta^2, \text{ and } \beta\alpha = \alpha^3\beta \rangle.
\]
One sees that $\alpha = i$ and $\beta = j$ in this definition.

\begin{exercise}\label{exercise-normal-subgroups-of-quarternion-group}
    Find all the normal subgroups of the quaternion group $\mathrm{Q}$.\newline
    (\textit{Hint: consider \myref{problem-subgroup-of-index-2}.})
\end{exercise}

\section{The Alternating Group}
The alternating group is a very important group in the field of group theory. However, before we can properly define it, we need to introduce the idea of transpositions and the parity of permutations.

\subsection{Transpositions}
\begin{definition}
    A \term{transposition}\index{transposition} is a 2-cycle. That is, in cycle notation, a transposition can be written as $\begin{pmatrix}a&b\end{pmatrix}$.
\end{definition}
For example, we see that $\begin{pmatrix}1&5\end{pmatrix}$, $\begin{pmatrix}4&7\end{pmatrix}$, $\begin{pmatrix}3&6\end{pmatrix}$ etc. are transpositions, while $\begin{pmatrix}1&4&5\end{pmatrix}$, $\begin{pmatrix}3&4&6&5&9\end{pmatrix}$, $\begin{pmatrix}1&3&4&5\end{pmatrix}$ etc. are not. One sees clearly that every transposition is its own inverse.

We call transpositions which has cycle decomposition $\begin{pmatrix}i&i+1\end{pmatrix}$ \term{adjacent transpositions}\index{transposition!adjacent}, and we may denote them by $\alpha$.

We look at one lemma which can help `break up' transpositions into a composition of adjacent transpositions.

\begin{lemma}\label{lemma-decompose-transposition}
    For brevity, let $\tau_{a,b} = (a\quad b)$ for any positive integers $a$ and $b$. Let $i$ and $d$ be positive integers. Then
    \begin{align*}
        &\tau_{i,i+d}\\
        &=\tau_{i,i+1}\tau_{i+1,i+2}\cdots\tau_{i+d-2,i+d-1}\tau_{i+d-1,i+d}\tau_{i+d-2,i+d-1}\cdots\tau_{i+1,i+2}\tau_{i,i+1}.
    \end{align*}
\end{lemma}

\begin{proof}
    We induct on $d$.

    When $d = 1$, note that clearly $\tau_{i,i+1} = \tau_{i,i+1}$ so the lemma holds for the base case.

    Assume that the given representation of $\tau_{i,i+d}$ holds for some positive integer $d$. Note this means that it holds for all $i$, including $i+1$. Then one sees that
    {
        \fontsize{11pt}{13pt}\selectfont
        \begin{align*}
            &\tau_{i, i+(d+1)}\\
            &= \tau_{i,i+1}\tau_{i+1,i+(d+1)}\tau_{i,i+1}\\
            &= \tau_{i,i+1}\tau_{(i+1),(i+1)+d}\tau_{i,i+1}\\
            &= \tau_{i,i+1}(\tau_{(i+1),(i+1)+1}\cdots\tau_{(i+1)+d-2,(i+1)+d-1}\tau_{(i+1)+d-1,(i+1)+d}\\
            &\quad\quad\tau_{(i+1)+d-2,(i+1)+d-1}\cdots\tau_{(i+1),(i+1)+1})\tau_{i,i+1}\\
            &= \tau_{i,i+1}\tau_{i+1,i+2}\cdots\tau_{i+(d+1)-2,i+(d+1)-1}\tau_{i+(d+1)-1,i+(d+1)}\\
            &\quad\quad\tau_{i+(d+1)-2,i+(d+1)-1}\cdots\tau_{i+1,i+2}\tau_{i,i+1}
        \end{align*}
    }
    which shows that $d+1$ works as well.
\end{proof}
\begin{remark}
    The representation of $\tau_{i,i+d}$ in \myref{lemma-decompose-transposition} uses $2d-1$ compositions.
\end{remark}
\begin{example}
    An adjacent transposition decomposition of $(4\quad9)$ is
    \[
        (4\quad 5)(5\quad 6)(6\quad 7)(7\quad 8)(8\quad 9)(7\quad 8)(6\quad 7)(5\quad 6)(4\quad 5).
    \]
\end{example}
\begin{exercise}
    Write the transposition $\begin{pmatrix}2&6\end{pmatrix}$ into a composition of adjacent transpositions.
\end{exercise}

\subsection{Links with Permutations}
\begin{lemma}\label{lemma-permutations-as-product-of-transpositions}
    Let $\sigma$ be a permutation in $\Sn{n}$. Then $\sigma$ can be expressed as a product of transpositions.
\end{lemma}
\begin{proof}[Proof (see {\cite[\S 80 Corollary]{clark_1984}})]
    For the identity $\id$ it can be expressed as $(a\quad b)(a \quad b)$. Otherwise, for any $k \geq 2$, we see that any permutation $\sigma = \begin{pmatrix}a_1 & a_2 & a_3 & \cdots & a_k\end{pmatrix}$ can be written as
    \[
        \sigma = \begin{pmatrix}a_1 & a_k\end{pmatrix}\begin{pmatrix}a_1 & a_{k-1}\end{pmatrix}\begin{pmatrix}a_1 & a_{k-2}\end{pmatrix}\cdots\begin{pmatrix}a_1 & a_3\end{pmatrix}\begin{pmatrix}a_1 & a_2\end{pmatrix}
    \]
    and so every permutation is a product of transpositions.
\end{proof}

We now look at the idea of inversions inside permutations.
\begin{definition}
    Let $\sigma$ be a permutation. An \term{inversion}\index{permutation!inversion} of $\sigma$ between $i$ and $j$ exists if and only if $i < j$ and $\sigma(i) > \sigma(j)$.
\end{definition}

\begin{example}
    In the permutation $\sigma = \begin{pmatrix}1 & 3 & 2 & 4\end{pmatrix}$, we see that $2 < 3$ but $\sigma(2) = 4 > 2 = \sigma(3)$. Thus there is an inversion between 2 and 3.
\end{example}

We now define the idea of even permutations and odd permutations.

\begin{definition}
    A permutation $\sigma$ is said to be \term{even}\index{permutation!even} if there are an even number of inversions in $\sigma$. If $\sigma$ is not even then it is said to be \term{odd}\index{permutation!odd}.
\end{definition}
\begin{remark}
    The evenness or oddness of a permutation $\sigma$ is called the \term{parity of $\sigma$}\index{permutation!parity}.
\end{remark}

Counting the number of inversions in a permutation may be hard to do, so we have a very helpful theorem on the parity of a permutation.

\begin{theorem}\label{thrm-parity-of-permutation}
    Let $\sigma$ be a permutation. Suppose $\sigma$ can be expressed as a product of $n$ transpositions. Then $\sigma$ is even if and only if $n$ is even.
\end{theorem}
\begin{proof}
    We only need to show that the parity of $n$ and the parity of the permutation $\sigma$ is the same to prove this.

    By \myref{lemma-permutations-as-product-of-transpositions}, all permutations can be produced by a sequence of transpositions, say $\sigma = \tau_1\tau_2\tau_3\cdots\tau_k$. By \myref{lemma-decompose-transposition}, every transposition can be written as a product of $2d - 1$ adjacent transpositions. Expressing each $\tau_i$ as a product of adjacent transpositions yields $\sigma = \alpha_1\alpha_2\cdots\alpha_m$ where $\alpha_i$ is an adjacent transposition for $1 \leq i \leq m$. Note that the parity of $m$ is the same as that of $k$.

    It is clear that for any permutation $\pi$ and adjacent permutation $\alpha$, the permutation $\alpha\pi$ has either one more or one less inversion than $\pi$. Thus the parity of the number of inversions of a permutation is switched when composed with adjacent transpositions.

    We note that the identity permutation $\id$ is an even permutation. So $\alpha_1$ is odd, $\alpha_1\alpha_2$ is even, $\alpha_1\alpha_2\alpha_3$ is odd, etc., so $\alpha_1\alpha_2\cdots\alpha_m$ has the parity of $m$. Therefore the parity of the number of inversions of $\sigma$ is the parity of $k$ (since $m$ and $k$ have the same parity).
\end{proof}

\begin{corollary}\label{corollary-permutation-and-inverse-have-same-parity}
    $\sigma$ and $\sigma^{-1}$ have the same parity for any permutation $\sigma$.
\end{corollary}
\begin{proof}
    One observes clearly that $\sigma\sigma^{-1} = \id$. Since $\id$ is even, thus $\sigma\sigma^{-1}$ must be composed of an even number of transpositions (\myref{thrm-parity-of-permutation}).
    \begin{itemize}
        \item If $\sigma$ is even, then $\sigma$ can be expressed as a product of an even number of transpositions. Hence $\sigma^{-1}$ must also be a product of an even number of transpositions in order for $\sigma\sigma^{-1} = \id$ to be even.
        \item If $\sigma$ is odd, then $\sigma$ can be expressed as a product of an odd number of transpositions. Hence $\sigma^{-1}$ must also be a product of an odd number of transpositions in order for $\sigma\sigma^{-1} = \id$ to be even.
    \end{itemize}
    This proves the claim.
\end{proof}

We look at one final useful construct: the sign of a permutation.

\begin{definition}
    The \term{sign of a permutation}\index{permutation!sign} is $+1$ if the permutation is even and $-1$ if the permutation is odd.
\end{definition}

\begin{definition}
    The \term{signum}\index{signum} function $\sgn: \Sn{n} \to \{1, -1\}$ is defined such that
    \[
        \sgn(\sigma) = (-1)^{N(\sigma)} = (-1)^m
    \]
    where $N(\sigma)$ is the number of inversions in $\sigma$ and $m$ is the number of transpositions in the decomposition of $\sigma$.
\end{definition}

\begin{exercise}
    Find $\sgn\left(\begin{pmatrix}1&3&2&5&4\end{pmatrix}\right)$.
\end{exercise}

One observes that the number of inversions in $\sigma\tau$ is the same as the sum of inversions in $\sigma$ and $\tau$ separately, which means
\[
    N(\sigma\tau) = N(\sigma) + N(\tau)
\]
and so
\begin{align*}
    \sgn(\sigma\tau) &= (-1)^{N(\sigma\tau)}\\
    &= (-1)^{N(\sigma) + N(\tau)}\\
    &= (-1)^{N(\sigma)}(-1)^{N(\tau)}\\
    &= \sgn(\sigma)\sgn(\tau).
\end{align*}
One can then quickly verify \myref{corollary-permutation-and-inverse-have-same-parity} by noting
\[
    1 = \sgn(\id) = \sgn(\sigma\sigma^{-1}) = \sgn(\sigma)\sgn(\sigma^{-1})
\]
which implies $\sgn(\sigma)$ and $\sgn(\sigma^{-1})$ have the same parity.

\subsection{The Alternating Group}
We are now ready to look at the alternating group.
\begin{definition}
    The \term{alternating group of degree $n$}\index{alternating group!of degree $n$}, denoted by $\An{n}$, is given by
    \[
        \An{n} = \left\{\sigma \in \Sn{n} \vert \sigma \text{ is even}\right\}
    \]
    for $n \geq 2$.
\end{definition}

\begin{proposition}\label{prop-An-normal-subgroup-of-Sn}
    $\An{n} \lhd \Sn{n}$ for any integer $n \geq 2$.
\end{proposition}
\begin{proof}
    Note that the identity function $\id \in \An{n}$ since $\id \in \Sn{n}$ and the identity is even.

    Suppose now that $\mu$ and $\sigma$ are in $\An{n}$. We will show that $\mu\sigma^{-1} \in \An{n}$. By \myref{lemma-permutations-as-product-of-transpositions}, we may write
    \[
        \mu = \tau_1\tau_2\cdots\tau_{2k} \text{ and } \sigma = \tau_1'\tau_2'\cdots\tau_{2m}'.
    \]
    We note that any transposition is its own inverse, that is $\tau = \tau^{-1}$. Hence $\sigma^{-1} = \tau_{2m}'\tau_{2m-1}'\cdots\tau_2'\tau_1'$, so
    \[
        \mu\sigma^{-1} = \underbrace{\tau_1\cdots\tau_{2k}\tau_{2m}'\cdots\tau_1'}_{2(k+m) \text{ transpositions}}
    \]
    is an even permutation, meaning $\mu\sigma^{-1} \in \An{n}$. So $\An{n} \leq \Sn{n}$ by subgroup test. But as $\An{n}$ contains only even permutations, thus $\An{n} < \Sn{n}$.

    Now take $\sigma \in \Sn{n}$ and $\mu \in \An{n}$. Note that
    \begin{align*}
        \sgn\left(\sigma\mu\sigma^{-1}\right) &= \sgn(\sigma)\sgn(\mu)\sgn\left(\sigma^{-1}\right)\\
        &= \sgn(\sigma)\sgn\left(\sigma^{-1}\right)\sgn(\mu)\\
        &= \sgn\left(\sigma\sigma^{-1}\right)\sgn(\mu)\\
        &= \sgn(\id)\sgn(\mu)\\
        &= \sgn(\mu).
    \end{align*}
    As $\mu$ is even, so $\sgn(\mu) = 1$. Hence $\sgn\left(\sigma\mu\sigma^{-1}\right) = 1$ which means that $\sigma\mu\sigma^{-1}$ is an even permutation. Therefore $\sigma\mu\sigma^{-1} \in \An{n}$, proving that $\An{n} \lhd \Sn{n}$.
\end{proof}

\begin{proposition}\label{prop-order-of-An}
    $|\An{n}| = \frac{n!}2$ for any integer $n \geq 2$.
\end{proposition}
\begin{proof}
    For brevity, let the set
    \[
        \mathrm{O}_n = \left\{\sigma \in \Sn{n} \vert \sigma \text{ is odd}\right\} = \Sn{n} \setminus \An{n}.
    \]
    Clearly $\An{n} \cup \mathrm{O}_n = \Sn{n}$ and $\An{n} \cap \mathrm{O}_n = \emptyset$.

    Define the map $f: \An{n} \to \mathrm{O}_n$ such that $\sigma \mapsto \begin{pmatrix}1 & 2\end{pmatrix}\sigma$. We show that this is a bijection.
    \begin{itemize}
        \item \textbf{Injective}: Let $\mu$ and $\sigma$ be in $\An{n}$ such that $f(\mu) = f(\sigma)$. This means that $\begin{pmatrix}1 & 2\end{pmatrix}\mu = \begin{pmatrix}1 & 2\end{pmatrix}\sigma$. Now since transpositions are their own self-inverse, thus left-applying $\begin{pmatrix}1 & 2\end{pmatrix}$ on both sides yields $\mu = \sigma$.

        \item \textbf{Surjective}: Let $\mu \in \mathrm{O}_n$. Write $\mu = \tau_1\tau_2\cdots\tau_{2k-1}$ where $\tau_i$ is a transposition. Clearly
        \[
            \mu = \underbrace{\begin{pmatrix}1 & 2\end{pmatrix}\begin{pmatrix}1 & 2\end{pmatrix}}_{\id}\tau_1\tau_2\cdots\tau_{2k-1}.
        \]
        Consider $\sigma = \begin{pmatrix}1 & 2\end{pmatrix}\tau_1\tau_2\cdots\tau_{2k-1} \in \An{n}$. We see that
        \begin{align*}
            f(\sigma) &= \begin{pmatrix}1 & 2\end{pmatrix}\sigma\\
            &= \begin{pmatrix}1 & 2\end{pmatrix}\left(\begin{pmatrix}1 & 2\end{pmatrix}\tau_1\tau_2\cdots\tau_{2k-1}\right)\\
            &= \tau_1\tau_2\cdots\tau_{2k-1}\\
            &= \mu
        \end{align*}
        and so any $\mu \in \mathrm{O}_n$ has a pre-image $\sigma \in \An{n}$.
    \end{itemize}
    This proves that $f$ is a bijection, meaning $|\An{n}| = |\mathrm{O}_n|$.

    Since $\An{n} \cup \mathrm{O}_n = \Sn{n}$ and $\An{n} \cap \mathrm{O}_n = \emptyset$, thus $|\Sn{n}| = |\An{n}| + |\mathrm{O}_n| = 2|\An{n}|$. Now because $|\Sn{n}| = n!$ by \myref{exercise-order-of-Sn}, therefore $|\An{n}| = \frac{n!}2$.
\end{proof}

\begin{exercise}
    List all elements of $\An{3}$.
\end{exercise}

\section{Group of Units Modulo $n$}\label{section-group-of-units-mod-n}
Let us now look at a useful group in Number Theory: the group of units modulo $n$.

\begin{definition}
    For a positive integer $n \geq 2$, the \term{group of units modulo $n$}\index{group of units modulo $n$}, denoted $\Un{n}$, is the set
    \[
        \Un{n} = \{m \in \Z \vert 1 \leq m < n \text{ and } \gcd(m, n) = 1\}
    \]
    under the operation $\otimes_n$ (multiplication modulo $n$).
\end{definition}

\begin{proposition}
    $\Un{n}$ is an abelian group.
\end{proposition}
\begin{proof}
    We first prove that $\Un{n}$ satisfies the four group axioms to show that $\Un{n}$ is a group.
    \begin{itemize}
        \item \textbf{Closure}: Let $x, y \in \Un{n}$. Then $\gcd(x, n) = \gcd(y, n) = 1$. Hence $\gcd(xy, n) = 1$ which means that $\gcd(x\otimes_ny,n)=1$. Therefore we conclude that $x\otimes_ny \in \Un{n}$.

        \item \textbf{Associativity}: Multiplication is associative (\myref{axiom-multiplication-is-associative}), so $\otimes_n$ is associative.

        \item \textbf{Identity}: Note that 1 is the identity in $\Un{n}$ since $1 \otimes_n x = x$.

        \item \textbf{Inverse}: Let $x \in \Un{n}$, meaning $\gcd(x, n) = 1$. Then \myref{prop-multiplicative-inverse-exists-iff-coprime} tells us that there exists an $m$ such that $mx \equiv 1 \pmod n$. Therefore $m \otimes_n x = 1$, which means $m$ is the inverse of $x$.
    \end{itemize}
    Now since multiplication is commutative (\myref{axiom-multiplication-is-commutative}), so multiplication modulo $n$ is also commutative. Hence one sees that $\Un{n}$ is an abelian group under $\otimes_n$.
\end{proof}

\begin{exercise}
    List the elements of $\Un{10}$.
\end{exercise}

There is another representation of $\Un{n}$, but we leave it to later in this section.

A useful Number Theory function that will occur frequently in this section is Euler's totient function.

\begin{definition}
    \term{Euler's totient function}\index{Euler's totient function} $\totient$ gives the number of positive integers that are smaller than and coprime to a positive integer $x$. That is,
    \[
        \totient(x) = \left|\{n \in \Z \vert 1 \leq n < x \text{ and } \gcd(n, x) = 1\}\right|.
    \]
    In particular, if $x = p_1^{n_1}p_2^{n_2}\cdots p_k^{n_k}$ where $p_1, p_2, \dots, p_k$ are \textbf{distinct} primes and $n_1,n_2,\dots,n_k$ are positive integers, then
    \[
        \totient(x) = x \left(1 - \frac1{p_1}\right)\left(1 - \frac1{p_2}\right)\cdots\left(1 - \frac1{p_k}\right).
    \]
\end{definition}
\begin{remark}
    By definition of $\Un{n}$, we see $|\Un{n}| = \totient(n)$.
\end{remark}

\begin{exercise}\label{exercise-order-of-a-divides-phi-a}
    Let $a \in \Un{n}$. Prove that $|a|$ divides $\totient(n)$.
\end{exercise}

We look at the specific case where an element of $\Un{n}$ has order $\totient(n)$.

\begin{definition}
    Let $a$ and $n$ be positive integers such that $a < n$. Suppose $\gcd(a, n) = 1$. Then $a$ is a \term{primitive root modulo $n$}\index{primitive root} if and only if $|a| = \totient(n)$ in $\Un{n}$.
\end{definition}

We note that we have a way to determine whether a primitive root modulo $n$ exists. However, the proof is way too complex to note down here, so we leave it as an axiom.
\begin{axiom}\label{axiom-primitive-root-modulo-p}
    There is a primitive root modulo $n$ if and only if $n$ is 1, 2, 4, $p^k$, or $2p^k$, where $p$ is an odd prime and $k$ is a positive integer.
\end{axiom}

\begin{proposition}\label{prop-Un-cyclic-only-if-exists-primitive-root}
    $\Un{n}$ is cyclic if and only if there is a primitive root modulo $n$.
\end{proposition}
\begin{proof}
    We first prove the forward direction. Let $\Un{n}$ be cyclic. Then there exists an element $r \in \Un{n}$ such that $|r| = |\Un{n}| = \totient(n)$. So $r$ is a primitive root modulo $n$.

    We now prove the reverse direction. Let $r \in \Un{n}$ be a primitive root modulo $n$. Then $\langle r \rangle \cong \Z_{\totient(n)}$. Note that since $|\langle r \rangle| = \totient(n) = |\Un{n}|$, therefore $r$ is a generator of $\Un{n}$, meaning $\Un{n}$ is cyclic.
\end{proof}
\begin{remark}
    In fact, what \myref{prop-Un-cyclic-only-if-exists-primitive-root} shows is that $\Un{n} \cong \Z_{\totient(n)}$ if there exists a primitive root modulo $n$.
\end{remark}

We end this section by looking at an alternate representation of $\Un{n}$.

\begin{definition}
    Define the group
    \[
        \left(\Z/(n\Z)\right)^{\times} = \left\{m + n\Z \ \vert \ m,n \in \Z,\; 1 \leq m < n,\; \gcd(m, n)=1\right\}
    \]
    under the operation $\ast$ where $(a+n\Z)\ast(b+n\Z) = (a\otimes_n b) + n\Z$ for $n \geq 2$.
\end{definition}
\begin{proposition}
    $\Un{n} \cong \left(\Z/(n\Z)\right)^{\times}$ for all positive integers $n \geq 2$.
\end{proposition}
\begin{proof}
    Define the map $\phi: \Un{n} \to \left(\Z/(n\Z)\right)^{\times}$ such that $m \mapsto m + n\Z$. We show that $\phi$ is an isomorphism.

    \begin{itemize}
        \item \textbf{Homomorphism}: Let $x, y \in \Un{n}$. Then $\phi$ is a homomorphism since
        \begin{align*}
            \phi(x \otimes_n y) &= (x \otimes_n y) + n\Z\\
            &= (x + n\Z) \ast (y + n\Z)\\
            &= \phi(x) \ast \phi(y).
        \end{align*}

        \item \textbf{Injective}: Suppose we have $x, y \in \Un{n}$ such that $\phi(x) = \phi(y)$. This means that $x + n\Z = y + n\Z$. Thus
        \[
            \{x + pn \vert p \in \Z \} = \ \{y + qn \vert q \in \Z \}.
        \]
        Hence we conclude that $x \equiv y \pmod{n}$. But since $1 \leq x, y < n$, we must have $x = y$. Therefore $\phi(x) = \phi(y)$ implies $x = y$, meaning $\phi$ is injective.

        \item \textbf{Surjective}: Let $x + n\Z \in (\Z/(n\Z))^\times$, so $\gcd(x,n) = 1$. Using Euclid's division lemma (\myref{lemma-euclid-division}) on $x$ yields $x = qn + r$, where $0 \leq r < n$. Note that
        \begin{align*}
            x + n\Z &= \{x + kn \vert k \in \Z\}\\
            &= \{(qn + r) + kn \vert k \in \Z\}\\
            &= \{r + n(\underbrace{q+k}_{\text{In } \Z}) \vertalt k \in \Z\}\\
            &= r + n\Z
        \end{align*}
        with $0 \leq r < n$. Note that if $r = 0$, this means that $x = qn$, which means that $\gcd(x, n) = \gcd(qn, n) = n \neq 1$, a contradiction. Thus, $r \neq 0$, meaning $1 \leq r < n$ and so $r \in \Un{n}$.

        Observing that $\phi(r) = r + n\Z = x + n\Z$ shows that $x + n\Z$ has a pre-image $r$ in $\Un{n}$, which means that $\phi$ is surjective.
    \end{itemize}

    Thus $\phi$ is an isomorphism, meaning $\Un{n} \cong \left(\Z/(n\Z)\right)^{\times}$.
\end{proof}

\section{Groups of Matrices}\label{section-groups-of-matrices}
\subsection{Introduction to Matrices}\label{subsection-intro-to-matrices}
Before we can introduce the groups of matrices, we need to understand what they are, and to learn some operations that can be applied to matrices.

A matrix\index{matrix} is a rectangular array of numbers, symbols, or expressions, arranged in rows and columns. They are used to represent mathematical objects or properties of objects. For example,
\[
    \mathbf{M} = \begin{pmatrix}
    1 & 2\\
    3 & 4\\
    5 & 6
    \end{pmatrix}
\]
is a matrix. In this book, we consider only square matrices\index{matrix!square}, which have the same number of rows as columns. For example,
\[
    \mathbf{A} = \begin{pmatrix}
    1 & 2 & 3\\
    4 & 5 & 6\\
    7 & 8 & 9
    \end{pmatrix}, \mathbf{B} = \begin{pmatrix}
    -1 & 0 & 1 & 1\\
    1 & 0 & -1 & 1\\
    1 & 1 & 1 & 1\\
    2 & 3 & 3 & 3
    \end{pmatrix}, \textrm{ and } \mathbf{C} = \begin{pmatrix}
    x & x^2\\
    x^3 & x^4\\
    \end{pmatrix}
\]
are square matrices. For brevity, for a matrix $\mathbf{M}$, we denote the element in the $i$th row and the $j$th column by $m_{i,j}$ (where $1 \leq i, j \leq n$ with $n$ being the number of rows and columns in $\mathbf{M}$). For example, using the above matrices, we see $a_{2,3} = 6$, $b_{2,4}=1$, and $c_{1,2} = x^2$.

We now introduce the idea of \term{matrix multiplication}\index{matrix!multiplication}. Consider two square matrices $\mathbf{A}$ and $\mathbf{B}$ with the same number of rows and columns (say, $n$ rows and columns). Let their product, denoted $\mathbf{AB}$, be the matrix $\mathbf{C}$. Then
\[
    c_{i,j} = \sum_{k=1}^n a_{i,k}b_{k,j}
\]
for any $1 \leq i, j \leq n$. For example, if $\mathbf{A} = \begin{pmatrix}1 & 2\\3 & 4\end{pmatrix}$ and $\mathbf{B} = \begin{pmatrix}5 & 6\\7 & 8\end{pmatrix}$ then
\[
    \textbf{AB} = \begin{pmatrix}1\times5+2\times7 & 1\times6+2\times8\\3\times5+4\times7 & 3\times6+4\times8\end{pmatrix}
    = \begin{pmatrix}19 & 22\\43 & 50\end{pmatrix}.
\]
Note that matrix multiplication is \textbf{not} commutative, as
\[
    \textbf{AB} = \begin{pmatrix}19 & 22\\43 & 50\end{pmatrix} \text{ but } \textbf{BA} = \begin{pmatrix}23 & 34\\31 & 46\end{pmatrix}.
\]

\begin{exercise}
    Find the matrix given by the product
    \[
        \begin{pmatrix}1&1&0\\0&1&0\\0&1&1\end{pmatrix}\begin{pmatrix}1&1&1\\1&0&1\\1&1&1\end{pmatrix}.
    \]
\end{exercise}

Matrices can also be `multiplied' by real numbers (known as \term{scalar multiplication}\index{scalar multiplication}). For example,
\[
    1.23\begin{pmatrix}1 & 2\\3 & 4\end{pmatrix} = \begin{pmatrix}1.23 & 2.46\\3.69 & 4.92\end{pmatrix}.
\]

We now look at a special kind of square matrix: the \term{identity matrix of order $n$}\index{matrix!identity}. It is denoted $\IdentityM{n}$ and it is a matrix with $n$ rows and columns with 1s on the main diagonal and 0s everywhere else. For example, we have
\[
    \IdentityM{2} = \begin{pmatrix}1 & 0\\0 & 1\end{pmatrix},
    \IdentityM{3} = \begin{pmatrix}1 & 0 & 0\\0 & 1 & 0\\0 & 0 & 1\end{pmatrix}, \text{ and }
    \IdentityM{4} = \begin{pmatrix}1 & 0 & 0 & 0\\0 & 1 & 0 & 0\\0 & 0 & 1 & 0\\0 & 0 & 0 & 1\end{pmatrix}.
\]
We note that for any matrix $\mathbf{M}$ with $n$ rows and columns,
\[
    \mathbf{M}\IdentityM{n} = \IdentityM{n}\mathbf{M} = \mathbf{M}.
\]

A square matrix may have an \term{inverse}\index{matrix!inverse}. Consider a square matrix $\mathbf{A}$ with $n$ rows and columns. Then $\mathbf{B}$ is an inverse of $\mathbf{A}$ if
\[
    \mathbf{AB} = \mathbf{BA} = \IdentityM{n}.
\]
For example, consider the matrices
\[
    \mathbf{A} = \begin{pmatrix}1&1&0\\ 0&1&0\\ 0&1&1\end{pmatrix} \text{ and } \mathbf{B} = \begin{pmatrix}1&-1&0\\0&1&0\\0&-1&1\end{pmatrix}.
\]
Note that
\[
    \textbf{AB} = \textbf{BA} = \IdentityM{3}
\]
so $\mathbf{B}$ is the inverse of $\mathbf{A}$ (and $\mathbf{A}$ is the inverse of $\mathbf{B}$). We denote the inverse of a square matrix $\mathbf{M}$ by $\mathbf{M}^{-1}$. We note that $\IdentityM{n}^{-1} = \IdentityM{n}$ since $\IdentityM{n}\IdentityM{n} = \IdentityM{n}$ by definition of the identity matrix.

One last thing we introduce here is the \term{determinant}\index{matrix!determinant}. The determinant is only well defined for square matrices, and, for a square matrix $\mathbf{A}$, is denoted by $\det(\mathbf{A})$ (or $\det \mathbf{A}$). The rule for the determinant changes as we increase the number of rows and columns in the square matrix, so we only look at small cases.
\begin{itemize}
    \item If the square matrix only has one row, then its determinant is the only element in the matrix. Thus, if $\mathbf{A} = (a_{1,1})$ then $\det \mathbf{A} = a_{1,1}$.
    \item If the square matrix has two rows, such as the matrix $\begin{pmatrix}a & b\\c & d\end{pmatrix}$, then its determinant is $ad-bc$.
    \item If the square matrix has three rows, like $\begin{pmatrix}a & b & c \\ d & e & f \\ g & h & i\end{pmatrix}$, then its determinant is $aei+bfg+cdh-ceg-bdi-afh$.
\end{itemize}
An important property of the determinant is that it is a multiplicative map --- for two square matrices $\mathbf{A}$ and $\mathbf{B}$,
\[
    \det (\mathbf{AB}) = \det(\mathbf{A}) \times \det(\mathbf{B}).
\]
Finally, not all square matrices has an inverse. The necessary and sufficient condition that determines whether a square matrix $\mathbf{M}$ has an inverse is whether $\det \mathbf{M} \neq 0$. That is,
\[
    \mathbf{M}^{-1} \text{ exists if and only if } \det \mathbf{M} \neq 0.
\]

We conclude this subsection with a few properties of the determinant that we state but not prove.
\begin{itemize}
    \item $\det(\IdentityM{n}) = 1$.
    \item $\det(\mathbf{M}^{-1}) = \left(\det \mathbf{M}\right)^{-1}$.
    \item $\det(k\mathbf{M}) = k^n \det\mathbf{M}$ for a matrix $\mathbf{M}$ with $n$ rows and columns.
\end{itemize}

\subsection{The General Linear Group Over the Real Numbers}\label{subsection-GLR-matrix-group}
With an introduction of matrices out of the way, we can introduce the first of two important matrix groups: the General Linear Group of degree $n$ over the real numbers.

\begin{definition}
    The \term{General Linear Group of degree $n$}\index{general linear group} over the real numbers is denoted by $\GL{n}{\R}$ and is the group with set
    \[
        \left\{\mathbf{M} \vert \mathbf{M} \text{ is a matrix with } n \text{ rows and columns, and } \det \mathbf{M} \neq 0\right\}
    \]
    under the operation of matrix multiplication.
\end{definition}
In other words, $\GL{n}{\R}$ is the group of real-valued matrices with $n$ rows and columns that has an inverse.

\begin{proposition}
    $\GL{n}{\R}$ is indeed a group under matrix multiplication.
\end{proposition}
\begin{proof}
    We need to prove the four group axioms.
    \begin{itemize}
        \item \textbf{Closure}: Consider two matrices $\mathbf{A}, \mathbf{B} \in \GL{n}{\R}$. Then that means that $\det \mathbf{A} \neq 0$ and $\det \mathbf{B} \neq 0$. Since $\det(\mathbf{AB}) = (\det \mathbf{A})(\det \mathbf{B})$, thus $\det(\mathbf{AB}) \neq 0$. Note also that $\textbf{AB}$ has $n$ rows and columns. Therefore $\textbf{AB} \in \GL{n}{\R}$, meaning that it is closed under matrix multiplication.

        \item \textbf{Associativity}: Consider three matrices $\mathbf{A}, \mathbf{B}, \mathbf{C} \in \GL{n}{\R}$.
        \begin{itemize}
            \item Consider $(\mathbf{AB})\mathbf{C}$. Let $\mathbf{R} = \mathbf{AB}$ and $\mathbf{S} = (\mathbf{AB})\mathbf{C}$. Then
            \[
                r_{i,k} = \sum_{l=1}^n a_{i,l}b_{l,k} \text{ and } s_{i,j} = \sum_{k=1}^n r_{i,k}c_{k,j}
            \]
            which means that
            \[
                s_{i,j} = \sum_{k=1}^n \left(\sum_{l=1}^n a_{i,l}b_{l,k}\right)c_{k,j} = \sum_{k=1}^n \sum_{l=1}^n (a_{i,l}b_{l,k})c_{k,j}.
            \]
            \item Now consider $\mathbf{A}(\mathbf{BC})$. Let $\mathbf{R} = \mathbf{BC}$ and $\mathbf{S} = \mathbf{A}(\mathbf{BC})$. Then
            \[
                r_{l,j} = \sum_{k=1}^nb_{l,k}c_{k,j} \text{ and } s_{i,j} = \sum_{l=1}^n a_{i,l}r_{l,j}
            \]
            which means that
            \[
                s_{i,j} = \sum_{l=1}^n a_{i,l}\left(\sum_{k=1}^nb_{l,k}c_{k,j}\right) = \sum_{l=1}^n\sum_{k=1}^n a_{i,l}(b_{l,k}c_{k,j}).
            \]
        \end{itemize}
        Now, multiplication is associative (\myref{axiom-multiplication-is-associative}). So
        \[
                (a_{i,l}b_{l,k})c_{k,j} = a_{i,l}(b_{l,k}c_{k,j})
        \]
        which means
        \[
            \sum_{k=1}^n \sum_{l=1}^n (a_{i,l}b_{l,k})c_{k,j} = \sum_{l=1}^n\sum_{k=1}^n a_{i,l}(b_{l,k}c_{k,j}),
        \]
        thereby proving that matrix multiplication is associative.

        \item \textbf{Identity}: We note that $\det \IdentityM{n} = 1 \neq 0$, so $\IdentityM{n} \in \GL{n}{\R}$. Since $\textbf{MI}_n = \IdentityM{n}\mathbf{M} = \mathbf{M}$ for any matrix $\mathbf{M} \in \GL{n}{\R}$, thus $\IdentityM{n}$ is the identity of $\GL{n}{\R}$.

        \item \textbf{Inverse}: Let $\mathbf{M} \in \GL{n}{\R}$. As $\det \mathbf{M} \neq 0$, thus $\mathbf{M}^{-1}$ exists. By the properties of the determinant, we see that $\det \left(\mathbf{M}^{-1}\right) = \left(\det \mathbf{M}\right)^{-1}$, and since $\det \mathbf{M} \neq 0$ thus $\det \mathbf{M}^{-1} \neq 0$. Hence $\mathbf{M}^{-1} \in \GL{n}{\R}$. Now because $\textbf{MM}^{-1} = \mathbf{M}^{-1}\mathbf{M} = \IdentityM{n}$, thus $\mathbf{M}^{-1}$ is the inverse of $\mathbf{M}$ in $\GL{n}{\R}$.
    \end{itemize}
    Therefore $\GL{n}{\R}$ is a group.
\end{proof}

\subsection{The Special Linear Group Over the Real Numbers}
We look at another group of matrices: the Special Linear Group of degree $n$ over the real numbers.

\begin{definition}
    The \term{Special Linear Group of degree $n$}\index{special linear group} over the real numbers is denoted by $\SL{n}{\R}$ and is the group with set
    \[
        \left\{\mathbf{M} \vert \mathbf{M}\text{ is a matrix with } n \text{ rows and columns, and } \det \mathbf{M} = 1\right\}
    \]
    under matrix multiplication.
\end{definition}

One sees clearly that $\SL{n}{\R}$ is a sub\textbf{set} of $\GL{n}{\R}$, where $\GL{n}{\R}$ requires non-zero determinant while the set of $\SL{n}{\R}$ requires the determinant to be 1, which satisfies the non-zero determinant requirement. What we want to prove here is that $\SL{n}{\R}$ is a sub\textbf{group} of $\GL{n}{\R}$. In fact, it is a normal subgroup of $\GL{n}{\R}$.

\begin{proposition}
    $\SL{n}{\R} \lhd \GL{n}{\R}$.
\end{proposition}
\begin{proof}
    We consider the subgroup test. Clearly $\IdentityM{n} \in \SL{n}{\R}$ since its determinant is 1.

    Let $\mathbf{A}, \mathbf{B} \in \SL{n}{\R}$. This means that $\det \mathbf{A} = 1$ and $\det \mathbf{B} = 1$. Note that $\det(\mathbf{B}^{-1}) = (\det \mathbf{B})^{-1} = 1^{-1} = 1$. Thus we see that $\det \textbf{AB}^{-1} = (\det \mathbf{A})(\det(\mathbf{B}^{-1})) = 1 \times 1  = 1$ which means that $\textbf{AB}^{-1} \in \SL{n}{\R}$. Hence by the subgroup test, $\SL{n}{\R} < \GL{n}{\R}$.

    Now we prove normality of $\SL{n}{\R}$. Let $\mathbf{M} \in \GL{n}{\R}$ and $\mathbf{N} \in \SL{n}{\R}$. We are to show that $\textbf{MNM}^{-1} \in \SL{n}{\R}$. Since $\mathbf{M} \in \GL{n}{\R}$ thus $\det \mathbf{M} \neq 0$, meaning $\det \mathbf{M}^{-1} = (\det \mathbf{M})^{-1} \neq 0$. Also, $\mathbf{N} \in \SL{n}{\R}$ implies $\det \mathbf{N} = 1$. Hence,
    \[
        \det\left(\textbf{MNM}^{-1}\right) = (\det \mathbf{M})(\det \mathbf{N})(\det \mathbf{M})^{-1} = \det \mathbf{N} = 1
    \]
    which means that $\textbf{MNM}^{-1} \in \SL{n}{\R}$.

    Therefore $\SL{n}{\R} \lhd \GL{n}{\R}$.
\end{proof}

\subsection{A Consequence of the First Isomorphism Theorem}
We end this section with a consequence of the First Isomorphism Theorem (\myref{thrm-isomorphism-1}) on these groups of matrices. For brevity, let $\R^\ast$ be the group of non-zero real numbers under multiplication.

\begin{proposition}
    $\GL{n}{\R} / \SL{n}{\R} \cong \R^\ast$.
\end{proposition}
\begin{proof}
    Define the map $\phi: \GL{n}{\R} \to \R^\ast$ where $\mathbf{M} \mapsto \det\mathbf{M}$.
	\begin{itemize}
	    \item \textbf{Homomorphism}: Take $\mathbf{M}, \mathbf{N} \in \GL{n}{\R}$. Then
	    \[
	        \phi(\textbf{MN}) = \det(\textbf{MN}) = \det(\mathbf{M})\det(\mathbf{N}) = \phi(\mathbf{M})\phi(\mathbf{N})
	    \]
	    which means that $\phi$ is a homomorphism.

	    \item \textbf{Image}: We prove that $\phi$ is surjective to show that $\im \phi = \R^\ast$. Suppose $r \in \R^\ast$. Then $r^{\frac1n} \in \R^\ast$, and a matrix with $r^{\frac1n}$ on its main diagonal (written as $r^{\frac1n}\IdentityM{n}$ where $\IdentityM{n}$ is the identity matrix with $n$ rows and columns) is in $\GL{n}{\R}$. Note that $\det\left(r^{\frac1n}\IdentityM{n}\right) = \left(r^{\frac1n}\right)^n\det(\IdentityM{n}) = r$. Thus there is a pre-image of $r$ inside the codomain $\R^\ast$, meaning that $\phi$ is surjective. Hence, $\im \phi = \R^\ast$.

	    \item \textbf{Kernel}: Note that 1 is the identity in $\R^\ast$. Thus
	    \begin{align*}
	        \ker\phi &= \{\mathbf{M} \in \GL{n}{\R} \vert \phi(\mathbf{M}) = 1\} \\
	        &= \{\mathbf{M} \in \GL{n}{\R} \vert \det(\mathbf{M}) = 1\}\\
	        &= \SL{n}{\R}.
	    \end{align*}
	\end{itemize}
	The First Isomorphism Theorem (\myref{thrm-isomorphism-1}) tells us that
	\[
	    \GL{n}{\R} / \SL{n}{\R} \cong \R^\ast
	\]
	which proves the claim.
\end{proof}

\section{Automorphism Groups}\label{section-automorphism-groups}
\subsection{The Group of Automorphisms}
We look at automorphisms, an important type of map in abstract algebra.

\begin{definition}
    An \term{automorphism}\index{automorphism} of a group $G$ is an isomorphism from a group $G$ to itself. That is, $\phi: G \to G$ is an automorphism if $\phi$ is an isomorphism.
\end{definition}

\begin{definition}
    Let $G$ be a group. The \term{group of automorphisms of $G$}\index{automorphism group} is denoted $\Aut{G}$ and given by
    \[
        \Aut{G} = \{\phi: G \to G \vert \phi \text{ is an isomorphism}\}
    \]
    under function composition (denoted by $\circ$).
\end{definition}

\begin{proposition}
    $\Aut{G}$ is indeed a group.
\end{proposition}
\begin{proof}
    We look at the four group axioms.
    \begin{itemize}
        \item \textbf{Closure}: If $f, g \in \Aut{G}$, and $h = fg$, then $h: G \to G$ is a bijection. Furthermore $h$ is a homomorphism since for any $x, y \in G$ we have
        \begin{align*}
            h(xy) &= f(g(xy))\\
            &= f(g(x)g(y)) & (g \text{ is an isomorphism})\\
            &= f(g(x))f(g(y)) & (f \text{ is an isomorphism})\\
            &= h(x)h(y)
        \end{align*}
        so $h$ is an isomorphism, meaning $h = fg \in \Aut{G}$.

        \item \textbf{Associativity}: Function composition is associative by \myref{axiom-function-composition-associative}.

        \item \textbf{Identity}: The identity isomorphism $\id: G \to G, g \mapsto g$ is in $\Aut{G}$. By definition of $\id$, we have $f \circ \id = f$ and $\id \circ f = f$, so $\id$ is indeed the identity in $\Aut{G}$.

        \item \textbf{Inverse}: Suppose $f \in \Aut{G}$. Then $f$ is an isomorphism. By \myref{thrm-isomorphism-consequences}, we know $f^{-1}: G \to G$ is also an isomorphism, so $f^{-1} \in \Aut{G}$. Recall also that
        \[
            f\circ f^{-1} = \id \text{ and } f^{-1}\circ f = \id
        \]
        so $f^{-1}$ is indeed the inverse of $f$.
    \end{itemize}
    Since the four group axioms are satisfied, thus $\Aut{G}$ is a group under function composition.
\end{proof}

\subsection{The Group of Inner Automorphisms}
\begin{definition}
    An \term{inner automorphism}\index{automorphism!inner} of a group $G$ is an automorphism $\iota: G \to G$ such that $\iota(x) = gxg^{-1}$ for some fixed $g \in G$.
\end{definition}

\begin{definition}
    Let $G$ be a group. The \term{group of inner automorphisms of $G$}\index{automorphism group!inner}, denoted $\Inn{G}$, is given by
    \[
        \Inn{G} = \{\iota_g: G \to G \vert \iota_g(x) = gxg^{-1},\; g \in G\}
    \]
    under function composition (denoted by $\circ$).
\end{definition}

\begin{proposition}
    For any group $G$, we have $\Inn{G} \leq \Aut{G}$.
\end{proposition}
\begin{proof}
    Clearly $\id \in \Inn{G}$ since $\id = \iota_e$ and
    \[
        \id(x) = \iota_e(x) = exe^{-1} = x.
    \]
    for any $x \in G$. Hence $\Inn{G}$ is non-empty.

    Now take $\iota_x, \iota_y \in \Inn{G}$. Note that $\left(\iota_y\right)^{-1} = \iota_{y^{-1}}$ since
    \[
        \left(\iota_y\right)\left(\iota_{y^{-1}}\right)(g) = \left(\iota_y\right)\left(y^{-1}gy\right) = y\left(y^{-1}gy\right)y^{-1} = g
    \]
    which means $\left(\iota_y\right)\left(\iota_{y^{-1}}\right) = \id$. Therefore $\iota_x\left(\iota_y\right)^{-1} = \iota_{xy^{-1}}$ since for any $g \in G$ we have
    \begin{align*}
        \iota_x\left(\iota_y\right)^{-1}(g) &= \iota_x\iota_{y^{-1}}(g)\\
        &= \iota_x\left(y^{-1}gy\right)\\
        &= xy^{-1}gyx^{-1}\\
        &= \left(xy^{-1}\right) g \left(xy^{-1}\right)^{-1}\\
        &= \iota_{xy^{-1}}(g),
    \end{align*}
    which means that $\iota_x\left(\iota_y\right)^{-1} = \iota_{xy^{-1}} \in \Inn{G}$.

    Hence, by subgroup test, $\Inn{G} \leq \Aut{G}$.
\end{proof}

\begin{exercise}
    Let $G$ be a group. Prove that $\Inn{G} \unlhd \Aut{G}$.
\end{exercise}

\subsection{A Consequence of the First Isomorphism Theorem}
Before we can state the consequence, we revisit the idea of the center of a group as introduced in \myref{example-center-of-group}.
\begin{quote}
    The center of a group $G$ is the normal subgroup
    \[
        \CenterGrp{G} = \{z \in G \vert z = gzg^{-1} \text{ for all } g \in G\}.
    \]
\end{quote}

\begin{proposition}
    For any group $G$, we have $G/\CenterGrp{G} \cong \Inn{G}$.
\end{proposition}
\begin{proof}
    We define the map $\phi: G \to \Inn{G}, g \mapsto \iota_g$, where $\iota_g(x) = gxg^{-1}$. We show that $\phi$ is a homomorphism, and then find its image and kernel.
    \begin{itemize}
        \item \textbf{Homomorphism}: Let $g, h \in G$. Then for any $x \in G$ we see
        \begin{align*}
            (\phi(gh))(x) = \iota_{gh}(x) &= (gh)x(gh)^{-1}\\
            &= gh x h^{-1}g^{-1}\\
            &= g(hxh^{-1})g^{-1}\\
            &= g(\iota_h(x))g^{-1}\\
            &=\iota_g(\iota_h(x))\\
            &=(\iota_g\circ\iota_h)(x)\\
            &=(\phi(g)\phi(h))(x)
        \end{align*}
        which means that $\phi$ is a homomorphism.

        \item \textbf{Image}: We show that $\phi$ is surjective to prove that $\im \phi = \Inn{G}$. Suppose $\iota_g \in \Inn{G}$. Clearly $\phi(g) = \iota_g$ which means that $\phi$ is surjective. Hence $\im\phi = \Inn{G}$.

        \item \textbf{Kernel}: Note that $\ker\phi = \{g \in G \vert \phi(g) = \id\}$. So, if $g \in \ker\phi$ then $(\phi(g))(x) = \iota_g(x) = \id(x) = x$ for all $x \in G$. This means that $gxg^{-1} = x$, meaning $gx = xg$ for all $x \in G$, so $g \in \CenterGrp{G}$. Hence $\ker\phi = \CenterGrp{G}$.
    \end{itemize}
    Thus, one sees that by the First Isomorphism Theorem (\myref{thrm-isomorphism-1}),
    \[
        G/\ker\phi \cong \im\phi,
    \]
    implying that
    \[
        G/\CenterGrp{G} \cong \Inn{G}.\qedhere
    \]
\end{proof}

\newpage

\section{Problems}
\begin{problem}
    Consider the group $\Z_{10101}$.
    \begin{partquestions}{\alph*}
        \item Find the smallest positive integer $a$ such that $1870a$ is a multiple of 10101.
        \item Find the smallest positive integer $b$ such that $3774b$ is a multiple of 10101.
    \end{partquestions}
\end{problem}

\begin{problem}
    Find the largest integer $n$ such that $\An{n}$ is an abelian group, proving your claim. Hence find all integers $k$ such that $\An{k}$ is cyclic.
\end{problem}

\begin{problem}
    Suppose $r$ is an odd primitive root modulo $p^k$, where $p$ is an odd prime and $k \geq 1$. Prove that $r$ is also a primitive root modulo $2p^k$.
\end{problem}

\begin{problem}
    Let $G$ be a cyclic group of order $n$ with generator $g$.
    \begin{partquestions}{\roman*}
        \item Suppose the maps $f_1: G \to G$ and $f_2: G \to G$ are homomorphisms. Prove that $f_1 = f_2$ if and only if $f_1(g) = f_2(g)$.

        \item Let the map $f: G \to G$ be a homomorphism. Explain why $f(g) = g^{m_f}$ for some $m_f \in \Z_n$.

        \item Show that the $m_f$ obtained in \textbf{(ii)} is unique to $f$.

        \item Suppose the functions $f_1: G \to G$ and $f_2: G \to G$ are homomorphisms. Prove that
        \[
            m_{f_1\circ f_2} = m_{f_1} \otimes_n m_{f_2}
        \]
        where $\circ$ denotes function composition and $\otimes_n$ denotes multiplication modulo $n$.

        \item Let the function $f: G \to G$ be a homomorphism. Prove that $f$ is an automorphism if and only if $m_f$ has a multiplicative inverse modulo $n$. That is, there exists $k \in \Un{n}$ such that $m_fk \equiv 1 \pmod n$ if and only if $f$ is an automorphism.\newline
        (\textit{Hint: \myref{prop-multiplicative-inverse-exists-iff-coprime} states that $ab \equiv 1 \pmod m$ if and only if $\gcd(a, m) = 1$.})

        \item Hence, by considering the map $\phi: \Aut{G} \to \Un{n}$ where $\phi(f) = m_f$, prove that
        \[
            \Aut{G} \cong \Un{n}.
        \]
    \end{partquestions}
\end{problem}
